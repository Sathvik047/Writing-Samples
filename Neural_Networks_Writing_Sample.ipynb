{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMk2oFUIIMGq",
        "outputId": "e038563a-1991-45f8-aeb2-b2f3d189fd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, random_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-zGHmoZITXC"
      },
      "source": [
        "\n",
        "# About this project  (Sathvik Thandra Neural Networks Writing Sample)\n",
        "\n",
        "# Image classification on CIFAR-10\n",
        "\n",
        "\n",
        "### Preliminaries information:\n",
        "In this problem we will explore different deep learning architectures for image classification on the CIFAR-10\n",
        "dataset. If you are not comfortable with PyTorch from the previous lecture and discussion materials, use the tutorials at http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html and make sure you\n",
        "are familiar with tensors, two-dimensional convolutions (`nn.Conv2d`) and fully-connected layers (`nn.Linear`),\n",
        "ReLU non-linearities (`F.relu`), pooling (`nn.MaxPool2d`), and tensor reshaping (`view`).\n",
        "\n",
        "\n",
        "\n",
        "- Each network $f$ maps an image $x^{\\rm in} \\in \\mb{R}^{32 \\times 32 \\times 3}$ (3 channels for RGB) to an output $f(x^{\\rm in}) = x^{\\rm out} \\in \\mb{R}^{10}$. The class label is predicted as $\\arg\\max_{i=0,1,\\dots,9} x_{i}^{\\rm out}$.\n",
        "\n",
        "- The network is trained via multiclass cross-entropy loss (log of softmax function).  Specifically, for an input image and label pair $(x^{\\rm in} , c)$ where $c\\in \\{0,\\dots, 9\\}$. If the networkâ€™s\n",
        "output layer is $x^{\\rm out} \\in \\mb{R}^{10}$, the loss $-\\log\\left(\\frac{\\exp(x_c^{\\rm out})}{\\sum_{c'} \\exp(x_{c'}^{\\rm out})}\\right)$.\n",
        "\n",
        "- For computational efficiency reasons, this particular network considers mini-batches of images per training\n",
        "step meaning the network actually maps $B=4$ images per feed-forward so that $\\tilde{x}^{\\rm in}\\in\\mb{R}^{B\\times 32 \\times 32 \\times 3}$ and $\\tilde{x}^{\\rm out}\\in\\mb{R}^{B\\times 10}$.  This is ignored in the network descriptions below but it is something to be aware of.\n",
        "\n",
        "- we will Create a validation dataset by appropriately partitioning the train dataset.\n",
        "\n",
        "- The cross-entropy loss for a neural network is, in general, non-convex. This means that the optimization\n",
        "method may converge to different local minima based on different hyperparameters of the optimization\n",
        "procedure (e.g., stepsize). Usually one can find a good setting for these hyperparameters by just observing\n",
        "the relative progress of training over the first epoch or two (how fast is it decreasing) but you are warned\n",
        "that early progress is not necessarily indicative of the final convergence value (you may converge quickly to a poor local minimum whereas a different step size could have poor early performance but converge to\n",
        "a better final value).\n",
        "\n",
        "- While one would usually train a network for hundreds of epochs to reach convergence and maximize accuracy, this can be prohibitively time-consuming, so feel free to train for just a a dozen or so epochs.\n",
        "\n",
        "\n",
        "Here we,\n",
        "\n",
        "- Report the hyperparameter configurations you evaluated and the best set of hyperparameters\n",
        "from this set.  \n",
        "\n",
        "- Plot the training and validation classification accuracy as a function of iteration. Produce\n",
        "a separate line or plot for each hyperparameter configuration evaluated (please try to use multiple lines in a single plot to keep the number of figures minimal).\n",
        "\n",
        "- Finally, evaluate your best set of\n",
        "hyperparameters on the test data and report the accuracy.\n",
        "\n",
        "\n",
        "\n",
        "The number of hyperparameters to tune, combined with the slow training times, will hopefully give\n",
        "you a taste of how difficult it is to construct networks with good generalization performance. It should be emphasized that the\n",
        "networks we constructed are **tiny**.\n",
        "State-of-the-art networks can have dozens of layers, each with their own hyperparameters to tune. Additional\n",
        "hyperparameters you are welcome to play with if you are so inclined, include: changing the activation\n",
        "function, replace max-pool with average-pool, adding more convolutional or fully connected layers, and\n",
        "experimenting with batch normalization or dropout.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXeS8QdNmrkH"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.set()\n",
        "torch.manual_seed(592)\n",
        "np.random.seed(592)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDIJJ4NVlvkz"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch_size=64, train_val_split_ratio=0.9):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    cifar10_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "    train_size = int(len(cifar10_set) * train_val_split_ratio)\n",
        "    val_size   = len(cifar10_set) - train_size\n",
        "\n",
        "    cifar10_trainset, cifar10_valset = torch.utils.data.random_split(cifar10_set, [train_size, val_size])\n",
        "    cifar10_testset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(cifar10_trainset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(cifar10_valset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(cifar10_testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7GFKr6PCDt6",
        "outputId": "0a6a021c-6945-4cf2-eae5-8c38f5b71c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = prepare_dataset(batch_size=64, train_val_split_ratio=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx0vnsaBC7Q0",
        "outputId": "d7d8c14e-8fce-4345-ec98-6fba7c5fe3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataLoader:\n",
            "Number of batches: 704\n",
            "Batch 1:\n",
            "Data shape: torch.Size([64, 3, 32, 32])\n",
            "Targets shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "print(\"Training DataLoader:\")\n",
        "print(\"Number of batches:\", len(train_loader))\n",
        "for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "    print(\"Data shape:\", data.shape)\n",
        "    print(\"Targets shape:\", targets.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8YfVYNeC7TQ",
        "outputId": "65cc34e9-85c8-4985-cbcd-aaccb4fc14b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation DataLoader:\n",
            "Number of batches: 79\n",
            "Batch 1:\n",
            "Data shape: torch.Size([64, 3, 32, 32])\n",
            "Targets shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nValidation DataLoader:\")\n",
        "print(\"Number of batches:\", len(val_loader))\n",
        "for batch_idx, (data, targets) in enumerate(val_loader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "    print(\"Data shape:\", data.shape)\n",
        "    print(\"Targets shape:\", targets.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYej1rmCC7Vw",
        "outputId": "8a1c877d-a1a1-4909-f1d1-3783703933d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test DataLoader:\n",
            "Number of batches: 157\n",
            "Batch 1:\n",
            "Data shape: torch.Size([64, 3, 32, 32])\n",
            "Targets shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# Printing information about the test loader\n",
        "print(\"\\nTest DataLoader:\")\n",
        "print(\"Number of batches:\", len(test_loader))\n",
        "for batch_idx, (data, targets) in enumerate(test_loader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "    print(\"Data shape:\", data.shape)\n",
        "    print(\"Targets shape:\", targets.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRLFZXYuxP27"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer, epochs, batch_size):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, targets)  # Calculate the loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Optimize\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_train += targets.size(0)\n",
        "            correct_train += predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = correct_train / total_train\n",
        "\n",
        "        # Validation\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                val_loss += criterion(outputs, targets).item()\n",
        "\n",
        "                _, predicted = outputs.max(1)\n",
        "                total_val += targets.size(0)\n",
        "                correct_val += predicted.eq(targets).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = correct_val / total_val\n",
        "\n",
        "        # Record statistics\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmePJ8gby2AJ"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, test_loader, criterion):\n",
        "\n",
        "    model.eval()  # Setting the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "            outputs = model(inputs)\n",
        "            test_loss += criterion(outputs, targets).item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_test += targets.size(0)\n",
        "            correct_test += predicted.eq(targets).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = correct_test / total_test\n",
        "\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn3WeaNXIc0g"
      },
      "source": [
        "##  Fully-connected output, no hidden layers (logistic regression)\n",
        "We begin with the simplest network\n",
        "possible that has no hidden layers and simply linearly maps the input layer to the output layer. That is,\n",
        "conceptually it could be written as\n",
        "\\begin{align*}\n",
        "    x^{\\rm out} &= W \\text{vec}(x^{\\rm in}) +b\n",
        "\\end{align*}\n",
        "where $x^{\\rm out} \\in \\mb{R}^{10}$, $x^{\\rm in} \\in \\mb{R}^{32 \\times 32 \\times 3}$, $W \\in \\mb{R}^{10 \\times 3072}$, $b \\in \\mb{R}^{10}$ since $3072 = 32 \\cdot 32 \\cdot 3$. For a tensor $x \\in \\mb{R}^{a \\times b \\times c}$, we let $\\text{vec}(x) \\in \\mb{R}^{a b c}$ be the reshaped form of the tensor into a vector (in an arbitrary but consistent pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrIf7zw5t5vR"
      },
      "outputs": [],
      "source": [
        "class LogisticRegressionWithSoftmax(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogisticRegressionWithSoftmax, self).__init__()\n",
        "        self.fc = nn.Linear(32 * 32 * 3, 10)  # Fully-connected layer without activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
        "        x = self.fc(x)  # Linear mapping to output layer\n",
        "        x = F.softmax(x, dim=1)  # Applying softmax activation along dimension 1 (classes)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppSZSyPdlrbC"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegressionWithSoftmax()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "epochs = 10\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJoQxGydX_iI",
        "outputId": "53f01292-1bc0-46a3-f12f-dbd9dd8625eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 2.1986, Train Acc: 0.2773, Val Loss: 2.1536, Val Acc: 0.3218\n",
            "Epoch 2/10, Train Loss: 2.1356, Train Acc: 0.3439, Val Loss: 2.1263, Val Acc: 0.3478\n",
            "Epoch 3/10, Train Loss: 2.1153, Train Acc: 0.3616, Val Loss: 2.1127, Val Acc: 0.3588\n",
            "Epoch 4/10, Train Loss: 2.1038, Train Acc: 0.3722, Val Loss: 2.1049, Val Acc: 0.3704\n",
            "Epoch 5/10, Train Loss: 2.0951, Train Acc: 0.3796, Val Loss: 2.0978, Val Acc: 0.3702\n",
            "Epoch 6/10, Train Loss: 2.0884, Train Acc: 0.3866, Val Loss: 2.0903, Val Acc: 0.3758\n",
            "Epoch 7/10, Train Loss: 2.0828, Train Acc: 0.3919, Val Loss: 2.0878, Val Acc: 0.3792\n",
            "Epoch 8/10, Train Loss: 2.0782, Train Acc: 0.3950, Val Loss: 2.0833, Val Acc: 0.3816\n",
            "Epoch 9/10, Train Loss: 2.0746, Train Acc: 0.3977, Val Loss: 2.0799, Val Acc: 0.3868\n",
            "Epoch 10/10, Train Loss: 2.0712, Train Acc: 0.4009, Val Loss: 2.0773, Val Acc: 0.3844\n"
          ]
        }
      ],
      "source": [
        "train_losses, train_accuracies, val_losses, val_accuracies = train(\n",
        "                model, train_loader, val_loader, criterion, optimizer, epochs, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNEcy-0hlpC1",
        "outputId": "4232e3c2-0301-43f8-a0d5-73a499fe5805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.0746, Test Acc: 0.3941\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = evaluation(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fully-connected output, no hidden layers (logistic regression)\n",
        "\n",
        "\n",
        "In our current model, which is consisting of a fully connected output layer (logistic regression) without hidden layers, we are directly mapping input to output using linear mapping and applying a softmax function at the output. However, due to the absence of activation functions, our model is clearly struggling to grasp complex patterns.\n",
        "\n",
        " Additionally, lacking hidden layers is limiting the models  ability to capture hierarchical features in the data and with a smaller number of parameters, the model's generalization performance is clearly low, and is achieving around 39% accuracy on the test dataset. Although training and validation accuracies are stable with fewer epochs and no signs of overfitting are observed.\n",
        "\n",
        "But I feel by enhancing the model and introducing activation functions and adding a hidden layer will improve the model's capacity to learn intricate patterns and hierarchical features so let us see how it performs in the later model."
      ],
      "metadata": {
        "id": "UppmLZZXp5Rb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1nkTyNuI-Q5"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Fully-connected output, 1 fully-connected hidden layer\n",
        "\n",
        "We will have one hidden layer denoted as $x^{\\rm hidden} \\in \\mb{R}^{M}$ where $M$ will be a hyperparameter you choose ($M$ could be in the hundreds). The non-linearity applied to the hidden layer will be the **relu** ($\\mathrm{relu}(x) = \\max\\{0,x\\}$, elementwise). This network can be written as\n",
        "\n",
        "\\begin{align*}\n",
        "    x^{\\rm out} &= W_2 \\mathrm{relu}(W_1 \\text{vec}(x^{\\rm in}) +b_1) + b_2\n",
        "\\end{align*}\n",
        "\n",
        "where $W_1 \\in \\mb{R}^{M \\times 3072}$, $b_1 \\in \\mb{R}^M$, $W_2 \\in \\mb{R}^{10 \\times M}$, $b_2 \\in \\mb{R}^{10}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3FS6gwRJCOw"
      },
      "outputs": [],
      "source": [
        "class FullyConnectedWithHiddenLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(FullyConnectedWithHiddenLayer, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input to hidden layer\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation to the hidden layer\n",
        "        x = self.fc2(x)  # Linear mapping to output layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dlYHMCGfZNZw",
        "outputId": "df0eb303-22ad-4128-8b50-857989d812a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 2.1890, Train Acc: 0.2064, Val Loss: 2.1045, Val Acc: 0.2554\n",
            "Epoch 2/10, Train Loss: 2.0466, Train Acc: 0.2866, Val Loss: 2.0063, Val Acc: 0.3056\n",
            "Epoch 3/10, Train Loss: 1.9640, Train Acc: 0.3197, Val Loss: 1.9401, Val Acc: 0.3292\n",
            "Epoch 4/10, Train Loss: 1.9057, Train Acc: 0.3416, Val Loss: 1.8912, Val Acc: 0.3442\n",
            "Epoch 5/10, Train Loss: 1.8624, Train Acc: 0.3558, Val Loss: 1.8543, Val Acc: 0.3516\n",
            "Epoch 6/10, Train Loss: 1.8280, Train Acc: 0.3644, Val Loss: 1.8297, Val Acc: 0.3646\n",
            "Epoch 7/10, Train Loss: 1.8006, Train Acc: 0.3738, Val Loss: 1.8016, Val Acc: 0.3720\n",
            "Epoch 8/10, Train Loss: 1.7777, Train Acc: 0.3830, Val Loss: 1.7772, Val Acc: 0.3770\n",
            "Epoch 9/10, Train Loss: 1.7582, Train Acc: 0.3898, Val Loss: 1.7624, Val Acc: 0.3836\n",
            "Epoch 10/10, Train Loss: 1.7409, Train Acc: 0.3942, Val Loss: 1.7518, Val Acc: 0.3900\n",
            "Epoch 1/10, Train Loss: 2.1807, Train Acc: 0.2356, Val Loss: 2.1002, Val Acc: 0.2762\n",
            "Epoch 2/10, Train Loss: 2.0431, Train Acc: 0.2950, Val Loss: 2.0072, Val Acc: 0.3062\n",
            "Epoch 3/10, Train Loss: 1.9641, Train Acc: 0.3204, Val Loss: 1.9384, Val Acc: 0.3282\n",
            "Epoch 4/10, Train Loss: 1.9064, Train Acc: 0.3401, Val Loss: 1.8877, Val Acc: 0.3452\n",
            "Epoch 5/10, Train Loss: 1.8625, Train Acc: 0.3556, Val Loss: 1.8494, Val Acc: 0.3586\n",
            "Epoch 6/10, Train Loss: 1.8278, Train Acc: 0.3678, Val Loss: 1.8156, Val Acc: 0.3686\n",
            "Epoch 7/10, Train Loss: 1.7987, Train Acc: 0.3779, Val Loss: 1.7959, Val Acc: 0.3750\n",
            "Epoch 8/10, Train Loss: 1.7739, Train Acc: 0.3857, Val Loss: 1.7705, Val Acc: 0.3818\n",
            "Epoch 9/10, Train Loss: 1.7528, Train Acc: 0.3935, Val Loss: 1.7611, Val Acc: 0.3890\n",
            "Epoch 10/10, Train Loss: 1.7340, Train Acc: 0.3987, Val Loss: 1.7360, Val Acc: 0.3938\n",
            "Epoch 1/10, Train Loss: 2.1692, Train Acc: 0.2445, Val Loss: 2.0887, Val Acc: 0.2840\n",
            "Epoch 2/10, Train Loss: 2.0273, Train Acc: 0.3050, Val Loss: 1.9889, Val Acc: 0.3150\n",
            "Epoch 3/10, Train Loss: 1.9476, Train Acc: 0.3306, Val Loss: 1.9269, Val Acc: 0.3316\n",
            "Epoch 4/10, Train Loss: 1.8916, Train Acc: 0.3491, Val Loss: 1.8756, Val Acc: 0.3482\n",
            "Epoch 5/10, Train Loss: 1.8495, Train Acc: 0.3624, Val Loss: 1.8438, Val Acc: 0.3598\n",
            "Epoch 6/10, Train Loss: 1.8166, Train Acc: 0.3726, Val Loss: 1.8131, Val Acc: 0.3698\n",
            "Epoch 7/10, Train Loss: 1.7886, Train Acc: 0.3816, Val Loss: 1.7857, Val Acc: 0.3766\n",
            "Epoch 8/10, Train Loss: 1.7660, Train Acc: 0.3889, Val Loss: 1.7715, Val Acc: 0.3816\n",
            "Epoch 9/10, Train Loss: 1.7451, Train Acc: 0.3980, Val Loss: 1.7509, Val Acc: 0.3884\n",
            "Epoch 10/10, Train Loss: 1.7267, Train Acc: 0.4034, Val Loss: 1.7333, Val Acc: 0.3954\n",
            "Epoch 1/10, Train Loss: 2.1825, Train Acc: 0.2279, Val Loss: 2.0958, Val Acc: 0.2798\n",
            "Epoch 2/10, Train Loss: 2.0418, Train Acc: 0.3017, Val Loss: 2.0012, Val Acc: 0.3094\n",
            "Epoch 3/10, Train Loss: 1.9613, Train Acc: 0.3280, Val Loss: 1.9384, Val Acc: 0.3320\n",
            "Epoch 4/10, Train Loss: 1.9048, Train Acc: 0.3478, Val Loss: 1.8844, Val Acc: 0.3444\n",
            "Epoch 5/10, Train Loss: 1.8633, Train Acc: 0.3599, Val Loss: 1.8554, Val Acc: 0.3590\n",
            "Epoch 6/10, Train Loss: 1.8300, Train Acc: 0.3696, Val Loss: 1.8319, Val Acc: 0.3678\n",
            "Epoch 7/10, Train Loss: 1.8033, Train Acc: 0.3764, Val Loss: 1.8012, Val Acc: 0.3742\n",
            "Epoch 8/10, Train Loss: 1.7804, Train Acc: 0.3848, Val Loss: 1.7870, Val Acc: 0.3788\n",
            "Epoch 9/10, Train Loss: 1.7609, Train Acc: 0.3895, Val Loss: 1.7632, Val Acc: 0.3854\n",
            "Epoch 10/10, Train Loss: 1.7435, Train Acc: 0.3956, Val Loss: 1.7462, Val Acc: 0.3910\n",
            "Epoch 1/10, Train Loss: 2.1716, Train Acc: 0.2433, Val Loss: 2.0879, Val Acc: 0.2804\n",
            "Epoch 2/10, Train Loss: 2.0339, Train Acc: 0.2959, Val Loss: 1.9955, Val Acc: 0.3096\n",
            "Epoch 3/10, Train Loss: 1.9562, Train Acc: 0.3230, Val Loss: 1.9287, Val Acc: 0.3258\n",
            "Epoch 4/10, Train Loss: 1.9011, Train Acc: 0.3415, Val Loss: 1.8869, Val Acc: 0.3436\n",
            "Epoch 5/10, Train Loss: 1.8596, Train Acc: 0.3548, Val Loss: 1.8473, Val Acc: 0.3530\n",
            "Epoch 6/10, Train Loss: 1.8260, Train Acc: 0.3668, Val Loss: 1.8135, Val Acc: 0.3604\n",
            "Epoch 7/10, Train Loss: 1.7982, Train Acc: 0.3760, Val Loss: 1.8000, Val Acc: 0.3700\n",
            "Epoch 8/10, Train Loss: 1.7748, Train Acc: 0.3835, Val Loss: 1.7727, Val Acc: 0.3784\n",
            "Epoch 9/10, Train Loss: 1.7545, Train Acc: 0.3916, Val Loss: 1.7579, Val Acc: 0.3840\n",
            "Epoch 10/10, Train Loss: 1.7361, Train Acc: 0.3989, Val Loss: 1.7470, Val Acc: 0.3888\n",
            "Epoch 1/10, Train Loss: 2.1713, Train Acc: 0.2494, Val Loss: 2.0885, Val Acc: 0.2768\n",
            "Epoch 2/10, Train Loss: 2.0283, Train Acc: 0.3034, Val Loss: 1.9888, Val Acc: 0.3074\n",
            "Epoch 3/10, Train Loss: 1.9482, Train Acc: 0.3286, Val Loss: 1.9258, Val Acc: 0.3310\n",
            "Epoch 4/10, Train Loss: 1.8921, Train Acc: 0.3452, Val Loss: 1.8823, Val Acc: 0.3474\n",
            "Epoch 5/10, Train Loss: 1.8497, Train Acc: 0.3593, Val Loss: 1.8417, Val Acc: 0.3618\n",
            "Epoch 6/10, Train Loss: 1.8156, Train Acc: 0.3706, Val Loss: 1.8122, Val Acc: 0.3698\n",
            "Epoch 7/10, Train Loss: 1.7879, Train Acc: 0.3816, Val Loss: 1.7895, Val Acc: 0.3746\n",
            "Epoch 8/10, Train Loss: 1.7645, Train Acc: 0.3890, Val Loss: 1.7680, Val Acc: 0.3800\n",
            "Epoch 9/10, Train Loss: 1.7433, Train Acc: 0.3972, Val Loss: 1.7482, Val Acc: 0.3884\n",
            "Epoch 10/10, Train Loss: 1.7248, Train Acc: 0.4018, Val Loss: 1.7294, Val Acc: 0.3968\n",
            "Epoch 1/10, Train Loss: 1.8880, Train Acc: 0.3414, Val Loss: 1.7507, Val Acc: 0.3802\n",
            "Epoch 2/10, Train Loss: 1.6849, Train Acc: 0.4150, Val Loss: 1.6608, Val Acc: 0.4112\n",
            "Epoch 3/10, Train Loss: 1.6024, Train Acc: 0.4436, Val Loss: 1.6174, Val Acc: 0.4370\n",
            "Epoch 4/10, Train Loss: 1.5471, Train Acc: 0.4642, Val Loss: 1.5649, Val Acc: 0.4450\n",
            "Epoch 5/10, Train Loss: 1.5049, Train Acc: 0.4783, Val Loss: 1.5430, Val Acc: 0.4528\n",
            "Epoch 6/10, Train Loss: 1.4710, Train Acc: 0.4900, Val Loss: 1.5261, Val Acc: 0.4606\n",
            "Epoch 7/10, Train Loss: 1.4399, Train Acc: 0.5018, Val Loss: 1.5017, Val Acc: 0.4750\n",
            "Epoch 8/10, Train Loss: 1.4129, Train Acc: 0.5121, Val Loss: 1.5105, Val Acc: 0.4676\n",
            "Epoch 9/10, Train Loss: 1.3873, Train Acc: 0.5202, Val Loss: 1.4843, Val Acc: 0.4824\n",
            "Epoch 10/10, Train Loss: 1.3630, Train Acc: 0.5299, Val Loss: 1.4603, Val Acc: 0.4882\n",
            "Epoch 1/10, Train Loss: 1.8978, Train Acc: 0.3397, Val Loss: 1.7549, Val Acc: 0.3902\n",
            "Epoch 2/10, Train Loss: 1.6802, Train Acc: 0.4162, Val Loss: 1.6448, Val Acc: 0.4280\n",
            "Epoch 3/10, Train Loss: 1.5958, Train Acc: 0.4459, Val Loss: 1.5961, Val Acc: 0.4464\n",
            "Epoch 4/10, Train Loss: 1.5397, Train Acc: 0.4657, Val Loss: 1.5671, Val Acc: 0.4480\n",
            "Epoch 5/10, Train Loss: 1.4981, Train Acc: 0.4821, Val Loss: 1.5481, Val Acc: 0.4526\n",
            "Epoch 6/10, Train Loss: 1.4618, Train Acc: 0.4934, Val Loss: 1.5063, Val Acc: 0.4738\n",
            "Epoch 7/10, Train Loss: 1.4275, Train Acc: 0.5081, Val Loss: 1.4780, Val Acc: 0.4830\n",
            "Epoch 8/10, Train Loss: 1.3963, Train Acc: 0.5177, Val Loss: 1.4700, Val Acc: 0.4796\n",
            "Epoch 9/10, Train Loss: 1.3672, Train Acc: 0.5310, Val Loss: 1.4570, Val Acc: 0.4914\n",
            "Epoch 10/10, Train Loss: 1.3401, Train Acc: 0.5404, Val Loss: 1.4316, Val Acc: 0.5022\n",
            "Epoch 1/10, Train Loss: 1.8886, Train Acc: 0.3433, Val Loss: 1.7418, Val Acc: 0.3944\n",
            "Epoch 2/10, Train Loss: 1.6718, Train Acc: 0.4187, Val Loss: 1.6366, Val Acc: 0.4254\n",
            "Epoch 3/10, Train Loss: 1.5856, Train Acc: 0.4505, Val Loss: 1.5817, Val Acc: 0.4462\n",
            "Epoch 4/10, Train Loss: 1.5280, Train Acc: 0.4705, Val Loss: 1.5376, Val Acc: 0.4640\n",
            "Epoch 5/10, Train Loss: 1.4814, Train Acc: 0.4876, Val Loss: 1.5085, Val Acc: 0.4674\n",
            "Epoch 6/10, Train Loss: 1.4409, Train Acc: 0.5036, Val Loss: 1.4818, Val Acc: 0.4866\n",
            "Epoch 7/10, Train Loss: 1.4038, Train Acc: 0.5165, Val Loss: 1.4654, Val Acc: 0.4856\n",
            "Epoch 8/10, Train Loss: 1.3714, Train Acc: 0.5280, Val Loss: 1.4502, Val Acc: 0.4948\n",
            "Epoch 9/10, Train Loss: 1.3393, Train Acc: 0.5410, Val Loss: 1.4334, Val Acc: 0.4952\n",
            "Epoch 10/10, Train Loss: 1.3110, Train Acc: 0.5526, Val Loss: 1.4163, Val Acc: 0.5024\n",
            "Epoch 1/10, Train Loss: 1.8957, Train Acc: 0.3368, Val Loss: 1.7574, Val Acc: 0.3890\n",
            "Epoch 2/10, Train Loss: 1.6897, Train Acc: 0.4116, Val Loss: 1.6554, Val Acc: 0.4186\n",
            "Epoch 3/10, Train Loss: 1.6080, Train Acc: 0.4411, Val Loss: 1.6073, Val Acc: 0.4326\n",
            "Epoch 4/10, Train Loss: 1.5539, Train Acc: 0.4608, Val Loss: 1.5630, Val Acc: 0.4540\n",
            "Epoch 5/10, Train Loss: 1.5114, Train Acc: 0.4768, Val Loss: 1.5497, Val Acc: 0.4522\n",
            "Epoch 6/10, Train Loss: 1.4762, Train Acc: 0.4908, Val Loss: 1.5126, Val Acc: 0.4722\n",
            "Epoch 7/10, Train Loss: 1.4453, Train Acc: 0.5026, Val Loss: 1.4988, Val Acc: 0.4774\n",
            "Epoch 8/10, Train Loss: 1.4163, Train Acc: 0.5129, Val Loss: 1.4916, Val Acc: 0.4782\n",
            "Epoch 9/10, Train Loss: 1.3887, Train Acc: 0.5230, Val Loss: 1.4883, Val Acc: 0.4852\n",
            "Epoch 10/10, Train Loss: 1.3636, Train Acc: 0.5303, Val Loss: 1.4578, Val Acc: 0.4896\n",
            "Epoch 1/10, Train Loss: 1.8874, Train Acc: 0.3447, Val Loss: 1.7424, Val Acc: 0.3932\n",
            "Epoch 2/10, Train Loss: 1.6769, Train Acc: 0.4173, Val Loss: 1.6494, Val Acc: 0.4240\n",
            "Epoch 3/10, Train Loss: 1.5933, Train Acc: 0.4473, Val Loss: 1.5868, Val Acc: 0.4464\n",
            "Epoch 4/10, Train Loss: 1.5374, Train Acc: 0.4664, Val Loss: 1.5524, Val Acc: 0.4526\n",
            "Epoch 5/10, Train Loss: 1.4946, Train Acc: 0.4842, Val Loss: 1.5289, Val Acc: 0.4654\n",
            "Epoch 6/10, Train Loss: 1.4589, Train Acc: 0.4951, Val Loss: 1.5086, Val Acc: 0.4682\n",
            "Epoch 7/10, Train Loss: 1.4253, Train Acc: 0.5090, Val Loss: 1.4745, Val Acc: 0.4874\n",
            "Epoch 8/10, Train Loss: 1.3938, Train Acc: 0.5190, Val Loss: 1.4670, Val Acc: 0.4780\n",
            "Epoch 9/10, Train Loss: 1.3664, Train Acc: 0.5301, Val Loss: 1.4514, Val Acc: 0.4944\n",
            "Epoch 10/10, Train Loss: 1.3393, Train Acc: 0.5415, Val Loss: 1.4393, Val Acc: 0.4962\n",
            "Epoch 1/10, Train Loss: 1.8839, Train Acc: 0.3460, Val Loss: 1.7479, Val Acc: 0.3850\n",
            "Epoch 2/10, Train Loss: 1.6684, Train Acc: 0.4199, Val Loss: 1.6436, Val Acc: 0.4248\n",
            "Epoch 3/10, Train Loss: 1.5841, Train Acc: 0.4516, Val Loss: 1.5800, Val Acc: 0.4518\n",
            "Epoch 4/10, Train Loss: 1.5277, Train Acc: 0.4701, Val Loss: 1.5411, Val Acc: 0.4570\n",
            "Epoch 5/10, Train Loss: 1.4833, Train Acc: 0.4892, Val Loss: 1.5139, Val Acc: 0.4648\n",
            "Epoch 6/10, Train Loss: 1.4432, Train Acc: 0.5025, Val Loss: 1.4943, Val Acc: 0.4770\n",
            "Epoch 7/10, Train Loss: 1.4070, Train Acc: 0.5148, Val Loss: 1.4794, Val Acc: 0.4802\n",
            "Epoch 8/10, Train Loss: 1.3746, Train Acc: 0.5292, Val Loss: 1.4793, Val Acc: 0.4828\n",
            "Epoch 9/10, Train Loss: 1.3436, Train Acc: 0.5399, Val Loss: 1.4397, Val Acc: 0.4992\n",
            "Epoch 10/10, Train Loss: 1.3139, Train Acc: 0.5511, Val Loss: 1.4277, Val Acc: 0.5054\n",
            "Epoch 1/10, Train Loss: 1.6780, Train Acc: 0.4044, Val Loss: 1.8848, Val Acc: 0.3504\n",
            "Epoch 2/10, Train Loss: 1.5046, Train Acc: 0.4707, Val Loss: 1.9795, Val Acc: 0.3968\n",
            "Epoch 3/10, Train Loss: 1.4228, Train Acc: 0.4987, Val Loss: 2.0728, Val Acc: 0.3976\n",
            "Epoch 4/10, Train Loss: 1.3677, Train Acc: 0.5236, Val Loss: 1.8929, Val Acc: 0.3948\n",
            "Epoch 5/10, Train Loss: 1.3182, Train Acc: 0.5409, Val Loss: 2.4118, Val Acc: 0.2958\n",
            "Epoch 6/10, Train Loss: 1.2802, Train Acc: 0.5527, Val Loss: 1.5485, Val Acc: 0.4754\n",
            "Epoch 7/10, Train Loss: 1.2439, Train Acc: 0.5671, Val Loss: 2.2050, Val Acc: 0.3738\n",
            "Epoch 8/10, Train Loss: 1.2116, Train Acc: 0.5781, Val Loss: 1.7815, Val Acc: 0.4432\n",
            "Epoch 9/10, Train Loss: 1.1759, Train Acc: 0.5893, Val Loss: 2.1135, Val Acc: 0.4064\n",
            "Epoch 10/10, Train Loss: 1.1481, Train Acc: 0.5990, Val Loss: 1.8003, Val Acc: 0.4464\n",
            "Epoch 1/10, Train Loss: 1.6665, Train Acc: 0.4112, Val Loss: 1.6836, Val Acc: 0.4082\n",
            "Epoch 2/10, Train Loss: 1.4813, Train Acc: 0.4788, Val Loss: 1.8424, Val Acc: 0.3842\n",
            "Epoch 3/10, Train Loss: 1.3932, Train Acc: 0.5162, Val Loss: 2.2657, Val Acc: 0.3542\n",
            "Epoch 4/10, Train Loss: 1.3348, Train Acc: 0.5344, Val Loss: 1.9352, Val Acc: 0.4014\n",
            "Epoch 5/10, Train Loss: 1.2786, Train Acc: 0.5556, Val Loss: 1.6383, Val Acc: 0.4760\n",
            "Epoch 6/10, Train Loss: 1.2333, Train Acc: 0.5752, Val Loss: 1.7403, Val Acc: 0.4332\n",
            "Epoch 7/10, Train Loss: 1.1903, Train Acc: 0.5877, Val Loss: 2.1287, Val Acc: 0.4062\n",
            "Epoch 8/10, Train Loss: 1.1491, Train Acc: 0.6046, Val Loss: 2.0931, Val Acc: 0.4232\n",
            "Epoch 9/10, Train Loss: 1.1102, Train Acc: 0.6166, Val Loss: 1.7161, Val Acc: 0.4842\n",
            "Epoch 10/10, Train Loss: 1.0867, Train Acc: 0.6278, Val Loss: 3.0257, Val Acc: 0.3850\n",
            "Epoch 1/10, Train Loss: 1.6597, Train Acc: 0.4140, Val Loss: 1.8561, Val Acc: 0.3670\n",
            "Epoch 2/10, Train Loss: 1.4747, Train Acc: 0.4816, Val Loss: 2.2422, Val Acc: 0.3166\n",
            "Epoch 3/10, Train Loss: 1.3870, Train Acc: 0.5144, Val Loss: 1.6369, Val Acc: 0.4400\n",
            "Epoch 4/10, Train Loss: 1.3171, Train Acc: 0.5425, Val Loss: 2.1687, Val Acc: 0.3860\n",
            "Epoch 5/10, Train Loss: 1.2612, Train Acc: 0.5659, Val Loss: 1.9304, Val Acc: 0.4046\n",
            "Epoch 6/10, Train Loss: 1.2099, Train Acc: 0.5799, Val Loss: 1.9514, Val Acc: 0.4118\n",
            "Epoch 7/10, Train Loss: 1.1649, Train Acc: 0.5996, Val Loss: 1.9500, Val Acc: 0.4234\n",
            "Epoch 8/10, Train Loss: 1.1170, Train Acc: 0.6170, Val Loss: 1.8258, Val Acc: 0.4538\n",
            "Epoch 9/10, Train Loss: 1.0738, Train Acc: 0.6356, Val Loss: 2.0419, Val Acc: 0.4380\n",
            "Epoch 10/10, Train Loss: 1.0359, Train Acc: 0.6470, Val Loss: 2.0628, Val Acc: 0.4196\n",
            "Epoch 1/10, Train Loss: 1.6819, Train Acc: 0.4066, Val Loss: 1.6770, Val Acc: 0.4044\n",
            "Epoch 2/10, Train Loss: 1.5004, Train Acc: 0.4771, Val Loss: 1.6067, Val Acc: 0.4426\n",
            "Epoch 3/10, Train Loss: 1.4208, Train Acc: 0.5028, Val Loss: 1.6374, Val Acc: 0.4352\n",
            "Epoch 4/10, Train Loss: 1.3640, Train Acc: 0.5246, Val Loss: 1.7062, Val Acc: 0.4174\n",
            "Epoch 5/10, Train Loss: 1.3126, Train Acc: 0.5424, Val Loss: 1.6147, Val Acc: 0.4518\n",
            "Epoch 6/10, Train Loss: 1.2755, Train Acc: 0.5559, Val Loss: 1.6927, Val Acc: 0.4442\n",
            "Epoch 7/10, Train Loss: 1.2377, Train Acc: 0.5706, Val Loss: 2.0263, Val Acc: 0.4142\n",
            "Epoch 8/10, Train Loss: 1.2044, Train Acc: 0.5801, Val Loss: 1.7727, Val Acc: 0.4548\n",
            "Epoch 9/10, Train Loss: 1.1783, Train Acc: 0.5894, Val Loss: 2.1679, Val Acc: 0.4054\n",
            "Epoch 10/10, Train Loss: 1.1497, Train Acc: 0.6023, Val Loss: 2.0590, Val Acc: 0.4196\n",
            "Epoch 1/10, Train Loss: 1.6736, Train Acc: 0.4078, Val Loss: 1.8054, Val Acc: 0.3770\n",
            "Epoch 2/10, Train Loss: 1.4860, Train Acc: 0.4776, Val Loss: 1.7593, Val Acc: 0.3990\n",
            "Epoch 3/10, Train Loss: 1.3987, Train Acc: 0.5116, Val Loss: 2.0139, Val Acc: 0.3782\n",
            "Epoch 4/10, Train Loss: 1.3331, Train Acc: 0.5361, Val Loss: 2.6160, Val Acc: 0.3302\n",
            "Epoch 5/10, Train Loss: 1.2787, Train Acc: 0.5572, Val Loss: 1.7249, Val Acc: 0.4356\n",
            "Epoch 6/10, Train Loss: 1.2322, Train Acc: 0.5734, Val Loss: 1.7043, Val Acc: 0.4628\n",
            "Epoch 7/10, Train Loss: 1.1865, Train Acc: 0.5870, Val Loss: 3.7447, Val Acc: 0.3310\n",
            "Epoch 8/10, Train Loss: 1.1605, Train Acc: 0.6008, Val Loss: 1.7830, Val Acc: 0.4670\n",
            "Epoch 9/10, Train Loss: 1.1101, Train Acc: 0.6160, Val Loss: 1.7228, Val Acc: 0.4676\n",
            "Epoch 10/10, Train Loss: 1.0791, Train Acc: 0.6321, Val Loss: 1.8961, Val Acc: 0.4604\n",
            "Epoch 1/10, Train Loss: 1.6625, Train Acc: 0.4115, Val Loss: 2.0654, Val Acc: 0.3278\n",
            "Epoch 2/10, Train Loss: 1.4738, Train Acc: 0.4830, Val Loss: 2.1718, Val Acc: 0.3566\n",
            "Epoch 3/10, Train Loss: 1.3933, Train Acc: 0.5138, Val Loss: 1.6211, Val Acc: 0.4468\n",
            "Epoch 4/10, Train Loss: 1.3141, Train Acc: 0.5426, Val Loss: 2.1543, Val Acc: 0.3864\n",
            "Epoch 5/10, Train Loss: 1.2627, Train Acc: 0.5626, Val Loss: 1.7898, Val Acc: 0.4422\n",
            "Epoch 6/10, Train Loss: 1.2044, Train Acc: 0.5870, Val Loss: 1.9192, Val Acc: 0.4282\n",
            "Epoch 7/10, Train Loss: 1.1658, Train Acc: 0.6016, Val Loss: 2.0234, Val Acc: 0.4448\n",
            "Epoch 8/10, Train Loss: 1.1169, Train Acc: 0.6196, Val Loss: 1.5537, Val Acc: 0.5054\n",
            "Epoch 9/10, Train Loss: 1.0750, Train Acc: 0.6344, Val Loss: 1.6337, Val Acc: 0.4882\n",
            "Epoch 10/10, Train Loss: 1.0293, Train Acc: 0.6512, Val Loss: 1.6014, Val Acc: 0.4966\n",
            "Best Hyperparameters: {'lr': 0.01, 'batch_size': 32, 'hidden_size': 512, 'optimizer': 'SGD'}\n",
            "Best Validation Accuracy: 0.4661999999999999\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "batch_sizes = [32, 64]\n",
        "hidden_sizes = [128, 256, 512]\n",
        "optimizer_class = optim.SGD\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 10\n",
        "\n",
        "best_hyperparams = {}\n",
        "best_val_accuracy = 0\n",
        "all_results = {}\n",
        "\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        for hidden_size in hidden_sizes:\n",
        "            model = FullyConnectedWithHiddenLayer(32 * 32 * 3, hidden_size, 10)\n",
        "            optimizer = optimizer_class(model.parameters(), lr=lr)\n",
        "\n",
        "            train_losses, train_accuracies, val_losses, val_accuracies = train(\n",
        "                model, train_loader, val_loader, nn.CrossEntropyLoss(), optimizer, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "            config_name = f\"lr={lr}_batch={batch_size}_hidden={hidden_size}_optimizer=SGD\"\n",
        "            all_results[config_name] = {\n",
        "                'train_losses': train_losses,\n",
        "                'train_accuracies': train_accuracies,\n",
        "                'val_losses': val_losses,\n",
        "                'val_accuracies': val_accuracies\n",
        "            }\n",
        "\n",
        "            avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
        "\n",
        "            if avg_val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = avg_val_accuracy\n",
        "                best_hyperparams = {'lr': lr, 'batch_size': batch_size, 'hidden_size': hidden_size, 'optimizer': 'SGD'}\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparams)\n",
        "print(\"Best Validation Accuracy:\", best_val_accuracy)\n",
        "\n",
        "best_config_name = f\"lr={best_hyperparams['lr']}_batch={best_hyperparams['batch_size']}_hidden={best_hyperparams['hidden_size']}_optimizer=SGD\"\n",
        "best_results = all_results[best_config_name]\n",
        "plt.plot(best_results['train_accuracies'], label='Train Accuracy')\n",
        "plt.plot(best_results['val_accuracies'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3K1kFifQ0cA"
      },
      "outputs": [],
      "source": [
        "model = FullyConnectedWithHiddenLayer(32*32*3, 512, 10)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhzTLBBncLUE",
        "outputId": "41305b63-1d33-4dc1-c4bb-3ba5e45d6d39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40, Train Loss: 1.8856, Train Acc: 0.3447, Val Loss: 1.7356, Val Acc: 0.3878\n",
            "Epoch 2/40, Train Loss: 1.6697, Train Acc: 0.4218, Val Loss: 1.6402, Val Acc: 0.4290\n",
            "Epoch 3/40, Train Loss: 1.5849, Train Acc: 0.4513, Val Loss: 1.5936, Val Acc: 0.4380\n",
            "Epoch 4/40, Train Loss: 1.5275, Train Acc: 0.4694, Val Loss: 1.5469, Val Acc: 0.4570\n",
            "Epoch 6/40, Train Loss: 1.4436, Train Acc: 0.5032, Val Loss: 1.4908, Val Acc: 0.4720\n",
            "Epoch 7/40, Train Loss: 1.4068, Train Acc: 0.5143, Val Loss: 1.4661, Val Acc: 0.4818\n",
            "Epoch 8/40, Train Loss: 1.3746, Train Acc: 0.5288, Val Loss: 1.4490, Val Acc: 0.4968\n",
            "Epoch 9/40, Train Loss: 1.3435, Train Acc: 0.5396, Val Loss: 1.4299, Val Acc: 0.5018\n",
            "Epoch 10/40, Train Loss: 1.3143, Train Acc: 0.5511, Val Loss: 1.4210, Val Acc: 0.5056\n",
            "Epoch 11/40, Train Loss: 1.2881, Train Acc: 0.5600, Val Loss: 1.4197, Val Acc: 0.5008\n",
            "Epoch 12/40, Train Loss: 1.2618, Train Acc: 0.5695, Val Loss: 1.4534, Val Acc: 0.4900\n",
            "Epoch 13/40, Train Loss: 1.2372, Train Acc: 0.5788, Val Loss: 1.4214, Val Acc: 0.4928\n",
            "Epoch 14/40, Train Loss: 1.2127, Train Acc: 0.5881, Val Loss: 1.3765, Val Acc: 0.5190\n",
            "Epoch 15/40, Train Loss: 1.1909, Train Acc: 0.5944, Val Loss: 1.4983, Val Acc: 0.4838\n",
            "Epoch 16/40, Train Loss: 1.1680, Train Acc: 0.6043, Val Loss: 1.3656, Val Acc: 0.5190\n",
            "Epoch 17/40, Train Loss: 1.1457, Train Acc: 0.6135, Val Loss: 1.3863, Val Acc: 0.5206\n",
            "Epoch 18/40, Train Loss: 1.1249, Train Acc: 0.6178, Val Loss: 1.3945, Val Acc: 0.5184\n",
            "Epoch 19/40, Train Loss: 1.1033, Train Acc: 0.6272, Val Loss: 1.3565, Val Acc: 0.5226\n",
            "Epoch 20/40, Train Loss: 1.0823, Train Acc: 0.6360, Val Loss: 1.3716, Val Acc: 0.5286\n",
            "Epoch 21/40, Train Loss: 1.0627, Train Acc: 0.6425, Val Loss: 1.3484, Val Acc: 0.5348\n",
            "Epoch 22/40, Train Loss: 1.0413, Train Acc: 0.6516, Val Loss: 1.3505, Val Acc: 0.5296\n",
            "Epoch 23/40, Train Loss: 1.0226, Train Acc: 0.6577, Val Loss: 1.3540, Val Acc: 0.5238\n",
            "Epoch 24/40, Train Loss: 1.0028, Train Acc: 0.6658, Val Loss: 1.3744, Val Acc: 0.5258\n",
            "Epoch 25/40, Train Loss: 0.9840, Train Acc: 0.6746, Val Loss: 1.3366, Val Acc: 0.5386\n",
            "Epoch 26/40, Train Loss: 0.9650, Train Acc: 0.6801, Val Loss: 1.3371, Val Acc: 0.5340\n",
            "Epoch 27/40, Train Loss: 0.9471, Train Acc: 0.6876, Val Loss: 1.3400, Val Acc: 0.5374\n",
            "Epoch 28/40, Train Loss: 0.9281, Train Acc: 0.6949, Val Loss: 1.3567, Val Acc: 0.5366\n",
            "Epoch 29/40, Train Loss: 0.9090, Train Acc: 0.7034, Val Loss: 1.3615, Val Acc: 0.5338\n",
            "Epoch 30/40, Train Loss: 0.8917, Train Acc: 0.7074, Val Loss: 1.5896, Val Acc: 0.4872\n",
            "Epoch 31/40, Train Loss: 0.8745, Train Acc: 0.7135, Val Loss: 1.3560, Val Acc: 0.5424\n",
            "Epoch 32/40, Train Loss: 0.8551, Train Acc: 0.7223, Val Loss: 1.3842, Val Acc: 0.5358\n",
            "Epoch 33/40, Train Loss: 0.8372, Train Acc: 0.7299, Val Loss: 1.3823, Val Acc: 0.5360\n",
            "Epoch 34/40, Train Loss: 0.8214, Train Acc: 0.7344, Val Loss: 1.3526, Val Acc: 0.5382\n",
            "Epoch 35/40, Train Loss: 0.8028, Train Acc: 0.7420, Val Loss: 1.3952, Val Acc: 0.5290\n",
            "Epoch 36/40, Train Loss: 0.7868, Train Acc: 0.7485, Val Loss: 1.4360, Val Acc: 0.5130\n",
            "Epoch 37/40, Train Loss: 0.7683, Train Acc: 0.7534, Val Loss: 1.3523, Val Acc: 0.5450\n",
            "Epoch 38/40, Train Loss: 0.7513, Train Acc: 0.7612, Val Loss: 1.3684, Val Acc: 0.5412\n",
            "Epoch 39/40, Train Loss: 0.7349, Train Acc: 0.7685, Val Loss: 1.3920, Val Acc: 0.5338\n",
            "Epoch 40/40, Train Loss: 0.7189, Train Acc: 0.7727, Val Loss: 1.3995, Val Acc: 0.5408\n"
          ]
        }
      ],
      "source": [
        "train_losses, train_accuracies, val_losses, val_accuracies = train(\n",
        "    model, train_loader, val_loader, criterion, optimizer, epochs=40, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ef9Uc-1Q0fA",
        "outputId": "c6e4e0dc-6b7a-4fd6-93ab-2182a1e37cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 1.3903, Test Acc: 0.5311\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = evaluation(model, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNkG_qIkJKW3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Convolutional layer with max-pool and fully-connected output (15pt)\n",
        "\n",
        "For a convolutional layer $W_1$ with filters of size $k \\times k \\times 3$, and $M$ filters (reasonable choices are $M=100$, $k=5$), we have that $\\mathrm{Conv2d}(x^{\\rm in}, W_1) \\in \\mb{R}^{(33-k) \\times (33-k) \\times M}$.\n",
        "\n",
        "- Each convolution will have its own offset applied to each of the output pixels of the convolution; we denote this as $\\mathrm{Conv2d}(x^{\\rm in}, W) + b_1$ where $b_1$ is parameterized in $\\mb{R}^M$. Apply a **relu** activation to the result of the convolutional layer.\n",
        "\n",
        "-  Next, use a max-pool of size $N \\times N$ (a reasonable choice is $N=14$ to pool to $2 \\times 2$ with $k=5$) we have that $\\textrm{MaxPool}( \\mathrm{relu}( \\mathrm{Conv2d}(x^{\\rm in}, W_1)+b_1)) \\in \\mb{R}^{\\lfloor\\frac{33-k}{N}\\rfloor \\times \\lfloor\\frac{33-k}{N}\\rfloor \\times M}$.\n",
        "\n",
        "- We will then apply a fully-connected layer to the output to get a final network given as\n",
        "\\begin{align*}\n",
        "          x^{\\rm output} = W_2 \\text{vec}(\\textrm{MaxPool}( \\mathrm{relu}( \\mathrm{Conv2d}(x^{\\rm input}, W_1)+b_1))) + b_2\n",
        "\\end{align*}\n",
        "where $W_2 \\in \\mb{R}^{10 \\times M (\\lfloor\\frac{33-k}{N}\\rfloor)^2}$, $b_2 \\in \\mb{R}^{10}$.\n",
        "\n",
        "\n",
        "The parameters $M, k, N$ (in addition to the step size and momentum) are all hyperparameters, but you\n",
        "can choose a reasonable value. Tune the different hyperparameters (number of convolutional filters, filter\n",
        "sizes, dimensionality of the fully-connected layers, stepsize, etc.) and train for a sufficient number of\n",
        "epochs to achieve a validation accuracy of **at least 70%**. Provide the hyperparameter configuration used\n",
        "to achieve this performance. Make sure to save this model so that you can do the next part.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVxbVoYYqeT1"
      },
      "outputs": [],
      "source": [
        "class ConvMaxPoolFullyConnected(nn.Module):\n",
        "    def __init__(self, num_filters, filter_size, max_pool_size, fc_input_size):\n",
        "        super(ConvMaxPoolFullyConnected, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, num_filters, kernel_size=filter_size)\n",
        "        self.fc_input_size = fc_input_size\n",
        "        self.fc = nn.Linear(fc_input_size, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=max_pool_size, stride=max_pool_size)\n",
        "        x = x.view(-1, self.fc_input_size)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnCh6D-TxbxP",
        "outputId": "a62a5f5d-68a0-4f00-9104-53ef14eaf834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15, Train Loss: 1.3735, Train Acc: 0.5190, Val Loss: 1.2104, Val Acc: 0.5786\n",
            "Epoch 2/15, Train Loss: 1.0701, Train Acc: 0.6286, Val Loss: 1.0752, Val Acc: 0.6274\n",
            "Epoch 3/15, Train Loss: 0.9550, Train Acc: 0.6711, Val Loss: 1.0367, Val Acc: 0.6404\n",
            "Epoch 4/15, Train Loss: 0.8833, Train Acc: 0.6975, Val Loss: 0.9953, Val Acc: 0.6578\n",
            "Epoch 5/15, Train Loss: 0.8280, Train Acc: 0.7178, Val Loss: 1.0113, Val Acc: 0.6532\n",
            "Epoch 6/15, Train Loss: 0.7800, Train Acc: 0.7337, Val Loss: 1.0147, Val Acc: 0.6584\n",
            "Epoch 7/15, Train Loss: 0.7402, Train Acc: 0.7470, Val Loss: 1.0199, Val Acc: 0.6734\n",
            "Epoch 8/15, Train Loss: 0.7052, Train Acc: 0.7606, Val Loss: 1.0032, Val Acc: 0.6696\n",
            "Epoch 9/15, Train Loss: 0.6664, Train Acc: 0.7730, Val Loss: 1.0491, Val Acc: 0.6612\n",
            "Epoch 10/15, Train Loss: 0.6357, Train Acc: 0.7840, Val Loss: 1.0135, Val Acc: 0.6696\n",
            "Epoch 11/15, Train Loss: 0.6097, Train Acc: 0.7909, Val Loss: 1.0496, Val Acc: 0.6564\n",
            "Epoch 12/15, Train Loss: 0.5819, Train Acc: 0.8009, Val Loss: 1.0445, Val Acc: 0.6650\n",
            "Epoch 13/15, Train Loss: 0.5536, Train Acc: 0.8118, Val Loss: 1.0975, Val Acc: 0.6618\n",
            "Epoch 14/15, Train Loss: 0.5304, Train Acc: 0.8189, Val Loss: 1.0781, Val Acc: 0.6650\n",
            "Epoch 15/15, Train Loss: 0.5092, Train Acc: 0.8276, Val Loss: 1.1089, Val Acc: 0.6636\n",
            "Epoch 1/20, Train Loss: 1.3950, Train Acc: 0.5079, Val Loss: 1.2066, Val Acc: 0.5720\n",
            "Epoch 2/20, Train Loss: 1.0865, Train Acc: 0.6258, Val Loss: 1.1360, Val Acc: 0.6086\n",
            "Epoch 3/20, Train Loss: 0.9704, Train Acc: 0.6650, Val Loss: 1.0630, Val Acc: 0.6434\n",
            "Epoch 4/20, Train Loss: 0.8914, Train Acc: 0.6961, Val Loss: 1.0406, Val Acc: 0.6422\n",
            "Epoch 5/20, Train Loss: 0.8365, Train Acc: 0.7114, Val Loss: 1.0170, Val Acc: 0.6568\n",
            "Epoch 6/20, Train Loss: 0.7886, Train Acc: 0.7300, Val Loss: 1.0094, Val Acc: 0.6640\n",
            "Epoch 7/20, Train Loss: 0.7508, Train Acc: 0.7449, Val Loss: 1.0152, Val Acc: 0.6608\n",
            "Epoch 8/20, Train Loss: 0.7176, Train Acc: 0.7539, Val Loss: 1.0254, Val Acc: 0.6606\n",
            "Epoch 9/20, Train Loss: 0.6834, Train Acc: 0.7666, Val Loss: 1.0293, Val Acc: 0.6672\n",
            "Epoch 10/20, Train Loss: 0.6482, Train Acc: 0.7788, Val Loss: 1.0410, Val Acc: 0.6676\n",
            "Epoch 11/20, Train Loss: 0.6205, Train Acc: 0.7876, Val Loss: 1.0538, Val Acc: 0.6650\n",
            "Epoch 12/20, Train Loss: 0.5968, Train Acc: 0.7952, Val Loss: 1.0471, Val Acc: 0.6652\n",
            "Epoch 13/20, Train Loss: 0.5668, Train Acc: 0.8059, Val Loss: 1.0495, Val Acc: 0.6628\n",
            "Epoch 14/20, Train Loss: 0.5434, Train Acc: 0.8148, Val Loss: 1.0917, Val Acc: 0.6614\n",
            "Epoch 15/20, Train Loss: 0.5214, Train Acc: 0.8218, Val Loss: 1.1548, Val Acc: 0.6542\n",
            "Epoch 16/20, Train Loss: 0.4994, Train Acc: 0.8312, Val Loss: 1.1135, Val Acc: 0.6666\n",
            "Epoch 17/20, Train Loss: 0.4770, Train Acc: 0.8391, Val Loss: 1.1872, Val Acc: 0.6598\n",
            "Epoch 18/20, Train Loss: 0.4601, Train Acc: 0.8442, Val Loss: 1.1448, Val Acc: 0.6558\n",
            "Epoch 19/20, Train Loss: 0.4425, Train Acc: 0.8511, Val Loss: 1.1520, Val Acc: 0.6646\n",
            "Epoch 20/20, Train Loss: 0.4212, Train Acc: 0.8580, Val Loss: 1.2153, Val Acc: 0.6556\n",
            "Epoch 1/25, Train Loss: 1.3881, Train Acc: 0.5113, Val Loss: 1.1813, Val Acc: 0.5948\n",
            "Epoch 2/25, Train Loss: 1.0997, Train Acc: 0.6195, Val Loss: 1.1260, Val Acc: 0.6124\n",
            "Epoch 3/25, Train Loss: 0.9737, Train Acc: 0.6659, Val Loss: 1.0420, Val Acc: 0.6386\n",
            "Epoch 4/25, Train Loss: 0.8965, Train Acc: 0.6929, Val Loss: 1.0517, Val Acc: 0.6462\n",
            "Epoch 5/25, Train Loss: 0.8438, Train Acc: 0.7104, Val Loss: 1.0154, Val Acc: 0.6624\n",
            "Epoch 6/25, Train Loss: 0.7964, Train Acc: 0.7272, Val Loss: 1.0487, Val Acc: 0.6568\n",
            "Epoch 7/25, Train Loss: 0.7524, Train Acc: 0.7435, Val Loss: 1.0033, Val Acc: 0.6708\n",
            "Epoch 8/25, Train Loss: 0.7162, Train Acc: 0.7547, Val Loss: 1.0021, Val Acc: 0.6686\n",
            "Epoch 9/25, Train Loss: 0.6869, Train Acc: 0.7664, Val Loss: 1.0293, Val Acc: 0.6660\n",
            "Epoch 10/25, Train Loss: 0.6519, Train Acc: 0.7774, Val Loss: 1.0169, Val Acc: 0.6674\n",
            "Epoch 11/25, Train Loss: 0.6188, Train Acc: 0.7911, Val Loss: 1.0385, Val Acc: 0.6646\n",
            "Epoch 12/25, Train Loss: 0.5945, Train Acc: 0.7983, Val Loss: 1.0510, Val Acc: 0.6570\n",
            "Epoch 13/25, Train Loss: 0.5635, Train Acc: 0.8090, Val Loss: 1.0829, Val Acc: 0.6608\n",
            "Epoch 14/25, Train Loss: 0.5416, Train Acc: 0.8170, Val Loss: 1.1198, Val Acc: 0.6634\n",
            "Epoch 15/25, Train Loss: 0.5219, Train Acc: 0.8248, Val Loss: 1.1152, Val Acc: 0.6630\n",
            "Epoch 16/25, Train Loss: 0.4949, Train Acc: 0.8337, Val Loss: 1.1253, Val Acc: 0.6640\n",
            "Epoch 17/25, Train Loss: 0.4755, Train Acc: 0.8399, Val Loss: 1.1260, Val Acc: 0.6630\n",
            "Epoch 18/25, Train Loss: 0.4582, Train Acc: 0.8447, Val Loss: 1.1688, Val Acc: 0.6574\n",
            "Epoch 19/25, Train Loss: 0.4405, Train Acc: 0.8519, Val Loss: 1.1754, Val Acc: 0.6592\n",
            "Epoch 20/25, Train Loss: 0.4218, Train Acc: 0.8592, Val Loss: 1.2296, Val Acc: 0.6376\n",
            "Epoch 21/25, Train Loss: 0.4047, Train Acc: 0.8639, Val Loss: 1.2602, Val Acc: 0.6504\n",
            "Epoch 22/25, Train Loss: 0.3921, Train Acc: 0.8682, Val Loss: 1.2068, Val Acc: 0.6544\n",
            "Epoch 23/25, Train Loss: 0.3784, Train Acc: 0.8733, Val Loss: 1.2688, Val Acc: 0.6520\n",
            "Epoch 24/25, Train Loss: 0.3570, Train Acc: 0.8818, Val Loss: 1.2580, Val Acc: 0.6466\n",
            "Epoch 25/25, Train Loss: 0.3490, Train Acc: 0.8852, Val Loss: 1.2479, Val Acc: 0.6566\n",
            "Epoch 1/15, Train Loss: 1.3728, Train Acc: 0.5187, Val Loss: 1.1820, Val Acc: 0.5942\n",
            "Epoch 2/15, Train Loss: 1.0814, Train Acc: 0.6270, Val Loss: 1.0639, Val Acc: 0.6344\n",
            "Epoch 3/15, Train Loss: 0.9610, Train Acc: 0.6712, Val Loss: 1.0540, Val Acc: 0.6512\n",
            "Epoch 4/15, Train Loss: 0.8892, Train Acc: 0.6964, Val Loss: 1.0230, Val Acc: 0.6514\n",
            "Epoch 5/15, Train Loss: 0.8316, Train Acc: 0.7154, Val Loss: 1.0516, Val Acc: 0.6388\n",
            "Epoch 6/15, Train Loss: 0.7855, Train Acc: 0.7317, Val Loss: 1.0076, Val Acc: 0.6594\n",
            "Epoch 7/15, Train Loss: 0.7441, Train Acc: 0.7449, Val Loss: 0.9994, Val Acc: 0.6670\n",
            "Epoch 8/15, Train Loss: 0.7087, Train Acc: 0.7564, Val Loss: 1.0377, Val Acc: 0.6660\n",
            "Epoch 9/15, Train Loss: 0.6749, Train Acc: 0.7690, Val Loss: 1.0437, Val Acc: 0.6606\n",
            "Epoch 10/15, Train Loss: 0.6409, Train Acc: 0.7813, Val Loss: 1.0258, Val Acc: 0.6646\n",
            "Epoch 11/15, Train Loss: 0.6143, Train Acc: 0.7892, Val Loss: 1.0588, Val Acc: 0.6592\n",
            "Epoch 12/15, Train Loss: 0.5831, Train Acc: 0.7992, Val Loss: 1.0548, Val Acc: 0.6596\n",
            "Epoch 13/15, Train Loss: 0.5606, Train Acc: 0.8093, Val Loss: 1.1085, Val Acc: 0.6580\n",
            "Epoch 14/15, Train Loss: 0.5370, Train Acc: 0.8172, Val Loss: 1.1349, Val Acc: 0.6564\n",
            "Epoch 15/15, Train Loss: 0.5097, Train Acc: 0.8260, Val Loss: 1.1009, Val Acc: 0.6680\n",
            "Epoch 1/20, Train Loss: 1.3830, Train Acc: 0.5146, Val Loss: 1.1720, Val Acc: 0.5994\n",
            "Epoch 2/20, Train Loss: 1.0805, Train Acc: 0.6296, Val Loss: 1.1546, Val Acc: 0.6026\n",
            "Epoch 3/20, Train Loss: 0.9672, Train Acc: 0.6680, Val Loss: 1.0349, Val Acc: 0.6396\n",
            "Epoch 4/20, Train Loss: 0.8958, Train Acc: 0.6945, Val Loss: 1.0140, Val Acc: 0.6550\n",
            "Epoch 5/20, Train Loss: 0.8424, Train Acc: 0.7109, Val Loss: 1.0261, Val Acc: 0.6504\n",
            "Epoch 6/20, Train Loss: 0.7912, Train Acc: 0.7303, Val Loss: 1.0031, Val Acc: 0.6654\n",
            "Epoch 7/20, Train Loss: 0.7563, Train Acc: 0.7409, Val Loss: 0.9896, Val Acc: 0.6692\n",
            "Epoch 8/20, Train Loss: 0.7170, Train Acc: 0.7564, Val Loss: 1.0185, Val Acc: 0.6608\n",
            "Epoch 9/20, Train Loss: 0.6802, Train Acc: 0.7690, Val Loss: 1.0139, Val Acc: 0.6674\n",
            "Epoch 10/20, Train Loss: 0.6474, Train Acc: 0.7800, Val Loss: 1.0183, Val Acc: 0.6664\n",
            "Epoch 11/20, Train Loss: 0.6177, Train Acc: 0.7906, Val Loss: 1.0535, Val Acc: 0.6580\n",
            "Epoch 12/20, Train Loss: 0.5896, Train Acc: 0.8001, Val Loss: 1.0573, Val Acc: 0.6644\n",
            "Epoch 13/20, Train Loss: 0.5593, Train Acc: 0.8123, Val Loss: 1.0772, Val Acc: 0.6628\n",
            "Epoch 14/20, Train Loss: 0.5334, Train Acc: 0.8210, Val Loss: 1.0700, Val Acc: 0.6688\n",
            "Epoch 15/20, Train Loss: 0.5120, Train Acc: 0.8262, Val Loss: 1.0923, Val Acc: 0.6736\n",
            "Epoch 16/20, Train Loss: 0.4913, Train Acc: 0.8342, Val Loss: 1.0935, Val Acc: 0.6654\n",
            "Epoch 17/20, Train Loss: 0.4675, Train Acc: 0.8440, Val Loss: 1.0920, Val Acc: 0.6712\n",
            "Epoch 18/20, Train Loss: 0.4463, Train Acc: 0.8493, Val Loss: 1.1178, Val Acc: 0.6638\n",
            "Epoch 19/20, Train Loss: 0.4289, Train Acc: 0.8563, Val Loss: 1.2123, Val Acc: 0.6524\n",
            "Epoch 20/20, Train Loss: 0.4086, Train Acc: 0.8633, Val Loss: 1.1765, Val Acc: 0.6592\n",
            "Epoch 1/25, Train Loss: 1.3582, Train Acc: 0.5260, Val Loss: 1.1478, Val Acc: 0.6052\n",
            "Epoch 2/25, Train Loss: 1.0511, Train Acc: 0.6381, Val Loss: 1.0404, Val Acc: 0.6468\n",
            "Epoch 3/25, Train Loss: 0.9450, Train Acc: 0.6795, Val Loss: 1.0255, Val Acc: 0.6430\n",
            "Epoch 4/25, Train Loss: 0.8783, Train Acc: 0.6979, Val Loss: 1.0542, Val Acc: 0.6354\n",
            "Epoch 5/25, Train Loss: 0.8285, Train Acc: 0.7145, Val Loss: 1.0113, Val Acc: 0.6508\n",
            "Epoch 6/25, Train Loss: 0.7790, Train Acc: 0.7343, Val Loss: 0.9811, Val Acc: 0.6684\n",
            "Epoch 7/25, Train Loss: 0.7438, Train Acc: 0.7463, Val Loss: 1.0352, Val Acc: 0.6606\n",
            "Epoch 8/25, Train Loss: 0.7067, Train Acc: 0.7556, Val Loss: 1.0307, Val Acc: 0.6606\n",
            "Epoch 9/25, Train Loss: 0.6767, Train Acc: 0.7671, Val Loss: 1.0169, Val Acc: 0.6618\n",
            "Epoch 10/25, Train Loss: 0.6403, Train Acc: 0.7805, Val Loss: 1.0417, Val Acc: 0.6648\n",
            "Epoch 11/25, Train Loss: 0.6145, Train Acc: 0.7901, Val Loss: 1.0809, Val Acc: 0.6572\n",
            "Epoch 12/25, Train Loss: 0.5858, Train Acc: 0.7992, Val Loss: 1.0768, Val Acc: 0.6546\n",
            "Epoch 13/25, Train Loss: 0.5593, Train Acc: 0.8106, Val Loss: 1.0861, Val Acc: 0.6634\n",
            "Epoch 14/25, Train Loss: 0.5317, Train Acc: 0.8194, Val Loss: 1.0802, Val Acc: 0.6582\n",
            "Epoch 15/25, Train Loss: 0.5106, Train Acc: 0.8252, Val Loss: 1.1087, Val Acc: 0.6596\n",
            "Epoch 16/25, Train Loss: 0.4879, Train Acc: 0.8342, Val Loss: 1.1158, Val Acc: 0.6580\n",
            "Epoch 17/25, Train Loss: 0.4754, Train Acc: 0.8394, Val Loss: 1.1532, Val Acc: 0.6514\n",
            "Epoch 18/25, Train Loss: 0.4539, Train Acc: 0.8471, Val Loss: 1.1404, Val Acc: 0.6670\n",
            "Epoch 19/25, Train Loss: 0.4343, Train Acc: 0.8531, Val Loss: 1.1946, Val Acc: 0.6412\n",
            "Epoch 20/25, Train Loss: 0.4146, Train Acc: 0.8604, Val Loss: 1.2187, Val Acc: 0.6434\n",
            "Epoch 21/25, Train Loss: 0.3959, Train Acc: 0.8664, Val Loss: 1.1805, Val Acc: 0.6590\n",
            "Epoch 22/25, Train Loss: 0.3878, Train Acc: 0.8706, Val Loss: 1.2178, Val Acc: 0.6532\n",
            "Epoch 23/25, Train Loss: 0.3684, Train Acc: 0.8771, Val Loss: 1.2174, Val Acc: 0.6538\n",
            "Epoch 24/25, Train Loss: 0.3575, Train Acc: 0.8812, Val Loss: 1.2498, Val Acc: 0.6504\n",
            "Epoch 25/25, Train Loss: 0.3404, Train Acc: 0.8884, Val Loss: 1.2895, Val Acc: 0.6478\n",
            "Epoch 1/15, Train Loss: 1.3596, Train Acc: 0.5239, Val Loss: 1.1649, Val Acc: 0.5996\n",
            "Epoch 2/15, Train Loss: 1.0602, Train Acc: 0.6341, Val Loss: 1.0873, Val Acc: 0.6244\n",
            "Epoch 3/15, Train Loss: 0.9490, Train Acc: 0.6749, Val Loss: 1.0233, Val Acc: 0.6454\n",
            "Epoch 4/15, Train Loss: 0.8801, Train Acc: 0.6974, Val Loss: 0.9992, Val Acc: 0.6676\n",
            "Epoch 5/15, Train Loss: 0.8268, Train Acc: 0.7171, Val Loss: 1.0301, Val Acc: 0.6578\n",
            "Epoch 6/15, Train Loss: 0.7854, Train Acc: 0.7308, Val Loss: 1.0257, Val Acc: 0.6614\n",
            "Epoch 7/15, Train Loss: 0.7396, Train Acc: 0.7468, Val Loss: 1.0536, Val Acc: 0.6544\n",
            "Epoch 8/15, Train Loss: 0.7017, Train Acc: 0.7589, Val Loss: 1.0385, Val Acc: 0.6510\n",
            "Epoch 9/15, Train Loss: 0.6665, Train Acc: 0.7722, Val Loss: 1.0398, Val Acc: 0.6554\n",
            "Epoch 10/15, Train Loss: 0.6401, Train Acc: 0.7820, Val Loss: 1.0426, Val Acc: 0.6678\n",
            "Epoch 11/15, Train Loss: 0.6059, Train Acc: 0.7928, Val Loss: 1.0700, Val Acc: 0.6568\n",
            "Epoch 12/15, Train Loss: 0.5820, Train Acc: 0.7996, Val Loss: 1.0889, Val Acc: 0.6504\n",
            "Epoch 13/15, Train Loss: 0.5522, Train Acc: 0.8126, Val Loss: 1.1022, Val Acc: 0.6568\n",
            "Epoch 14/15, Train Loss: 0.5302, Train Acc: 0.8201, Val Loss: 1.0981, Val Acc: 0.6612\n",
            "Epoch 15/15, Train Loss: 0.5080, Train Acc: 0.8302, Val Loss: 1.1170, Val Acc: 0.6592\n",
            "Epoch 1/20, Train Loss: 1.3437, Train Acc: 0.5299, Val Loss: 1.1720, Val Acc: 0.6018\n",
            "Epoch 2/20, Train Loss: 1.0592, Train Acc: 0.6342, Val Loss: 1.0570, Val Acc: 0.6370\n",
            "Epoch 3/20, Train Loss: 0.9467, Train Acc: 0.6743, Val Loss: 1.0447, Val Acc: 0.6402\n",
            "Epoch 4/20, Train Loss: 0.8776, Train Acc: 0.6979, Val Loss: 1.0816, Val Acc: 0.6424\n",
            "Epoch 5/20, Train Loss: 0.8257, Train Acc: 0.7167, Val Loss: 1.0029, Val Acc: 0.6638\n",
            "Epoch 6/20, Train Loss: 0.7806, Train Acc: 0.7342, Val Loss: 1.0212, Val Acc: 0.6662\n",
            "Epoch 7/20, Train Loss: 0.7369, Train Acc: 0.7501, Val Loss: 1.0369, Val Acc: 0.6560\n",
            "Epoch 8/20, Train Loss: 0.6960, Train Acc: 0.7643, Val Loss: 1.0649, Val Acc: 0.6592\n",
            "Epoch 9/20, Train Loss: 0.6641, Train Acc: 0.7738, Val Loss: 1.0492, Val Acc: 0.6654\n",
            "Epoch 10/20, Train Loss: 0.6359, Train Acc: 0.7847, Val Loss: 1.0272, Val Acc: 0.6758\n",
            "Epoch 11/20, Train Loss: 0.6030, Train Acc: 0.7931, Val Loss: 1.0392, Val Acc: 0.6676\n",
            "Epoch 12/20, Train Loss: 0.5727, Train Acc: 0.8055, Val Loss: 1.0744, Val Acc: 0.6676\n",
            "Epoch 13/20, Train Loss: 0.5464, Train Acc: 0.8136, Val Loss: 1.1184, Val Acc: 0.6498\n",
            "Epoch 14/20, Train Loss: 0.5217, Train Acc: 0.8226, Val Loss: 1.1043, Val Acc: 0.6664\n",
            "Epoch 15/20, Train Loss: 0.4989, Train Acc: 0.8313, Val Loss: 1.1016, Val Acc: 0.6696\n",
            "Epoch 16/20, Train Loss: 0.4754, Train Acc: 0.8380, Val Loss: 1.1091, Val Acc: 0.6684\n",
            "Epoch 17/20, Train Loss: 0.4582, Train Acc: 0.8440, Val Loss: 1.1640, Val Acc: 0.6566\n",
            "Epoch 18/20, Train Loss: 0.4363, Train Acc: 0.8540, Val Loss: 1.1535, Val Acc: 0.6580\n",
            "Epoch 19/20, Train Loss: 0.4260, Train Acc: 0.8575, Val Loss: 1.1902, Val Acc: 0.6564\n",
            "Epoch 20/20, Train Loss: 0.4063, Train Acc: 0.8644, Val Loss: 1.2235, Val Acc: 0.6588\n",
            "Epoch 1/25, Train Loss: 1.3785, Train Acc: 0.5188, Val Loss: 1.1504, Val Acc: 0.5922\n",
            "Epoch 2/25, Train Loss: 1.0799, Train Acc: 0.6247, Val Loss: 1.0808, Val Acc: 0.6226\n",
            "Epoch 3/25, Train Loss: 0.9691, Train Acc: 0.6653, Val Loss: 1.1205, Val Acc: 0.6234\n",
            "Epoch 4/25, Train Loss: 0.8938, Train Acc: 0.6918, Val Loss: 1.0230, Val Acc: 0.6494\n",
            "Epoch 5/25, Train Loss: 0.8383, Train Acc: 0.7124, Val Loss: 1.0123, Val Acc: 0.6528\n",
            "Epoch 6/25, Train Loss: 0.7966, Train Acc: 0.7279, Val Loss: 1.0078, Val Acc: 0.6616\n",
            "Epoch 7/25, Train Loss: 0.7537, Train Acc: 0.7414, Val Loss: 1.0157, Val Acc: 0.6676\n",
            "Epoch 8/25, Train Loss: 0.7135, Train Acc: 0.7577, Val Loss: 1.0088, Val Acc: 0.6676\n",
            "Epoch 9/25, Train Loss: 0.6757, Train Acc: 0.7693, Val Loss: 1.0453, Val Acc: 0.6562\n",
            "Epoch 10/25, Train Loss: 0.6468, Train Acc: 0.7792, Val Loss: 1.0543, Val Acc: 0.6660\n",
            "Epoch 11/25, Train Loss: 0.6152, Train Acc: 0.7911, Val Loss: 1.0726, Val Acc: 0.6514\n",
            "Epoch 12/25, Train Loss: 0.5926, Train Acc: 0.7988, Val Loss: 1.0551, Val Acc: 0.6592\n",
            "Epoch 13/25, Train Loss: 0.5621, Train Acc: 0.8081, Val Loss: 1.0982, Val Acc: 0.6602\n",
            "Epoch 14/25, Train Loss: 0.5366, Train Acc: 0.8185, Val Loss: 1.0929, Val Acc: 0.6626\n",
            "Epoch 15/25, Train Loss: 0.5158, Train Acc: 0.8260, Val Loss: 1.1460, Val Acc: 0.6444\n",
            "Epoch 16/25, Train Loss: 0.4937, Train Acc: 0.8329, Val Loss: 1.1256, Val Acc: 0.6600\n",
            "Epoch 17/25, Train Loss: 0.4738, Train Acc: 0.8406, Val Loss: 1.1519, Val Acc: 0.6596\n",
            "Epoch 18/25, Train Loss: 0.4517, Train Acc: 0.8472, Val Loss: 1.1463, Val Acc: 0.6552\n",
            "Epoch 19/25, Train Loss: 0.4306, Train Acc: 0.8557, Val Loss: 1.1545, Val Acc: 0.6584\n",
            "Epoch 20/25, Train Loss: 0.4162, Train Acc: 0.8600, Val Loss: 1.1887, Val Acc: 0.6512\n",
            "Epoch 21/25, Train Loss: 0.4043, Train Acc: 0.8639, Val Loss: 1.2371, Val Acc: 0.6496\n",
            "Epoch 22/25, Train Loss: 0.3804, Train Acc: 0.8738, Val Loss: 1.2219, Val Acc: 0.6628\n",
            "Epoch 23/25, Train Loss: 0.3634, Train Acc: 0.8801, Val Loss: 1.2398, Val Acc: 0.6582\n",
            "Epoch 24/25, Train Loss: 0.3594, Train Acc: 0.8816, Val Loss: 1.2802, Val Acc: 0.6416\n",
            "Epoch 25/25, Train Loss: 0.3384, Train Acc: 0.8907, Val Loss: 1.3221, Val Acc: 0.6490\n",
            "Epoch 1/15, Train Loss: 2.0142, Train Acc: 0.3118, Val Loss: 1.8929, Val Acc: 0.3590\n",
            "Epoch 2/15, Train Loss: 1.8272, Train Acc: 0.3801, Val Loss: 1.7909, Val Acc: 0.3930\n",
            "Epoch 3/15, Train Loss: 1.7480, Train Acc: 0.4062, Val Loss: 1.7347, Val Acc: 0.4116\n",
            "Epoch 4/15, Train Loss: 1.6953, Train Acc: 0.4237, Val Loss: 1.6912, Val Acc: 0.4286\n",
            "Epoch 5/15, Train Loss: 1.6539, Train Acc: 0.4383, Val Loss: 1.6585, Val Acc: 0.4446\n",
            "Epoch 6/15, Train Loss: 1.6182, Train Acc: 0.4520, Val Loss: 1.6241, Val Acc: 0.4490\n",
            "Epoch 7/15, Train Loss: 1.5876, Train Acc: 0.4615, Val Loss: 1.5904, Val Acc: 0.4564\n",
            "Epoch 8/15, Train Loss: 1.5585, Train Acc: 0.4719, Val Loss: 1.5777, Val Acc: 0.4644\n",
            "Epoch 9/15, Train Loss: 1.5314, Train Acc: 0.4811, Val Loss: 1.5464, Val Acc: 0.4684\n",
            "Epoch 10/15, Train Loss: 1.5068, Train Acc: 0.4885, Val Loss: 1.5275, Val Acc: 0.4862\n",
            "Epoch 11/15, Train Loss: 1.4836, Train Acc: 0.4968, Val Loss: 1.5042, Val Acc: 0.4828\n",
            "Epoch 12/15, Train Loss: 1.4622, Train Acc: 0.5039, Val Loss: 1.4770, Val Acc: 0.4974\n",
            "Epoch 13/15, Train Loss: 1.4412, Train Acc: 0.5112, Val Loss: 1.4666, Val Acc: 0.5024\n",
            "Epoch 14/15, Train Loss: 1.4225, Train Acc: 0.5170, Val Loss: 1.4498, Val Acc: 0.5006\n",
            "Epoch 15/15, Train Loss: 1.4042, Train Acc: 0.5226, Val Loss: 1.4306, Val Acc: 0.5062\n",
            "Epoch 1/20, Train Loss: 2.0020, Train Acc: 0.3163, Val Loss: 1.8760, Val Acc: 0.3606\n",
            "Epoch 2/20, Train Loss: 1.8123, Train Acc: 0.3845, Val Loss: 1.7750, Val Acc: 0.3886\n",
            "Epoch 3/20, Train Loss: 1.7338, Train Acc: 0.4100, Val Loss: 1.7170, Val Acc: 0.4216\n",
            "Epoch 4/20, Train Loss: 1.6828, Train Acc: 0.4277, Val Loss: 1.6732, Val Acc: 0.4320\n",
            "Epoch 5/20, Train Loss: 1.6413, Train Acc: 0.4420, Val Loss: 1.6411, Val Acc: 0.4346\n",
            "Epoch 6/20, Train Loss: 1.6069, Train Acc: 0.4544, Val Loss: 1.6081, Val Acc: 0.4516\n",
            "Epoch 7/20, Train Loss: 1.5756, Train Acc: 0.4649, Val Loss: 1.5811, Val Acc: 0.4602\n",
            "Epoch 8/20, Train Loss: 1.5471, Train Acc: 0.4738, Val Loss: 1.5558, Val Acc: 0.4730\n",
            "Epoch 9/20, Train Loss: 1.5202, Train Acc: 0.4832, Val Loss: 1.5308, Val Acc: 0.4758\n",
            "Epoch 10/20, Train Loss: 1.4949, Train Acc: 0.4918, Val Loss: 1.5130, Val Acc: 0.4686\n",
            "Epoch 11/20, Train Loss: 1.4713, Train Acc: 0.4986, Val Loss: 1.4939, Val Acc: 0.4808\n",
            "Epoch 12/20, Train Loss: 1.4500, Train Acc: 0.5060, Val Loss: 1.4681, Val Acc: 0.4964\n",
            "Epoch 13/20, Train Loss: 1.4294, Train Acc: 0.5139, Val Loss: 1.4506, Val Acc: 0.5036\n",
            "Epoch 14/20, Train Loss: 1.4111, Train Acc: 0.5200, Val Loss: 1.4297, Val Acc: 0.5092\n"
          ]
        }
      ],
      "source": [
        "num_filters_list = [128, 256, 512\n",
        "filter_size_list = [3, 5, 7]\n",
        "max_pool_size_list = [2, 3, 4]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_hyperparameters = {}\n",
        "\n",
        "for num_filters in num_filters_list:\n",
        "    for filter_size in filter_size_list:\n",
        "        for max_pool_size in max_pool_size_list:\n",
        "            fc_input_size = num_filters * ((33 - filter_size) // max_pool_size) ** 2\n",
        "            model = ConvMaxPoolFullyConnected(num_filters, filter_size, max_pool_size, fc_input_size)\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            train_losses, train_accuracies, val_losses, val_accuracies = train(\n",
        "                model, train_loader, val_loader, criterion, optimizer, epochs=15, batch_size=64)\n",
        "            avg_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
        "            if avg_val_accuracy > best_accuracy:\n",
        "                best_accuracy = avg_val_accuracy\n",
        "                best_hyperparameters = {\n",
        "                    'num_filters': num_filters,\n",
        "                    'filter_size': filter_size,\n",
        "                    'max_pool_size': max_pool_size,\n",
        "                    'fc_input_size': fc_input_size\n",
        "                }\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
        "print(\"Best Validation Accuracy:\", best_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5eGPdKpJXJk"
      },
      "source": [
        "# findings:\n",
        "\n",
        "Reaching a 70% validation accuracy involves playing around with different settings for our CNN model in a methodical way. We're essentially tweaking things like how many filters it uses, the size of those filters, and how it pools information. Each change affects how the model learns and performs. For example, having more filters can help the model pick up on more detailed features, but it might also make things slower. Likewise, adjusting the filter sizes can impact whether the model focuses on tiny details or broader patterns. Plus, deciding how aggressively to pool information can affect how much detail the model retains. It's a bit like finding the right balance between studying every detail and getting the big picture. We can also update the learning rate and optimize to help with the validation accuracy.\n",
        "\n",
        "Unfortunately, the max we got was 68%. So tweaking more would he=lp us get the result we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxRhwXJjLFoW"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## More tuning\n",
        "\n",
        "Return to the original network you were left with at the end of the tutorial Training\n",
        "a classifier. (Note that this is not the network above.) Tune the different hyperparameters\n",
        "(number of convolutional filters, filter sizes, dimensionality of the fully-connected layers, stepsize, etc.) and\n",
        "train for a sufficient number of iterations to achieve a *train accuracy* of **at least 87%**. You may not modify\n",
        "the core structure of the model (i.e., adding additional layers). Provide the hyperparameter configuration\n",
        "used to achieve this performance. Make sure to save this model so that you can do the next part (see\n",
        "the Training a classifier tutorial for details on how to do this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0URQB5cLnfB",
        "outputId": "6cbb9f93-23be-4ede-9fec-346ccb5ae9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.247\n",
            "[1,  4000] loss: 1.952\n",
            "[1,  6000] loss: 1.730\n",
            "[1,  8000] loss: 1.623\n",
            "[1, 10000] loss: 1.527\n",
            "[1, 12000] loss: 1.459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2,  2000] loss: 1.393\n",
            "[2,  4000] loss: 1.328\n",
            "[2,  6000] loss: 1.326\n",
            "[2,  8000] loss: 1.264\n",
            "[2, 10000] loss: 1.249\n",
            "[2, 12000] loss: 1.211\n",
            "[3,  2000] loss: 1.135\n",
            "[3,  4000] loss: 1.125\n",
            "[3,  6000] loss: 1.093\n",
            "[3,  8000] loss: 1.096\n",
            "[3, 10000] loss: 1.070\n",
            "[3, 12000] loss: 1.038\n",
            "[4,  2000] loss: 0.965\n",
            "[4,  4000] loss: 0.953\n",
            "[4,  6000] loss: 0.942\n",
            "[4,  8000] loss: 0.925\n",
            "[4, 10000] loss: 0.947\n",
            "[4, 12000] loss: 0.926\n",
            "[5,  2000] loss: 0.812\n",
            "[5,  4000] loss: 0.826\n",
            "[5,  6000] loss: 0.826\n",
            "[5,  8000] loss: 0.834\n",
            "[5, 10000] loss: 0.838\n",
            "[5, 12000] loss: 0.817\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 68.68 %\n"
          ]
        }
      ],
      "source": [
        "#  your code starts here\n",
        "import torch.optim as optim\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Updated hyperparameters\n",
        "num_conv_filters = 32\n",
        "conv_filter_size = 3\n",
        "fc1_output_size = 512\n",
        "fc2_output_size = 256\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 5\n",
        "\n",
        "# Define your neural network\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(3, num_conv_filters, conv_filter_size)\n",
        "       self.pool = nn.MaxPool2d(2, 2)\n",
        "       self.conv2 = nn.Conv2d(num_conv_filters, 16, conv_filter_size)\n",
        "       self.fc1 = nn.Linear(16 * 6 * 6, fc1_output_size)\n",
        "       self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
        "       self.fc3 = nn.Linear(fc2_output_size, 10)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.pool(F.relu(self.conv1(x)))\n",
        "       x = self.pool(F.relu(self.conv2(x)))\n",
        "       x = torch.flatten(x, 1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   running_loss = 0.0\n",
        "   for i, data in enumerate(trainloader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = net(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       running_loss += loss.item()\n",
        "       if i % 2000 == 1999:\n",
        "           print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "           running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "   for data in testloader:\n",
        "       images, labels = data\n",
        "       outputs = net(images)\n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "torch.save(net.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqAcvn-tM2l0"
      },
      "source": [
        "Accuracy is 67.53%, let us update the hyper parameters again. Tweak some to see what result we get. We will keep the epoch down to 5, to make sure it runs quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzFauJ8-M1Yl",
        "outputId": "b24d41f2-53a0-4ccd-ede4-48e9cb9c2f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.171\n",
            "[1,  4000] loss: 1.809\n",
            "[1,  6000] loss: 1.618\n",
            "[1,  8000] loss: 1.521\n",
            "[1, 10000] loss: 1.459\n",
            "[1, 12000] loss: 1.407\n",
            "[2,  2000] loss: 1.336\n",
            "[2,  4000] loss: 1.294\n",
            "[2,  6000] loss: 1.259\n",
            "[2,  8000] loss: 1.230\n",
            "[2, 10000] loss: 1.195\n",
            "[2, 12000] loss: 1.165\n",
            "[3,  2000] loss: 1.082\n",
            "[3,  4000] loss: 1.075\n",
            "[3,  6000] loss: 1.070\n",
            "[3,  8000] loss: 1.052\n",
            "[3, 10000] loss: 1.032\n",
            "[3, 12000] loss: 1.018\n",
            "[4,  2000] loss: 0.917\n",
            "[4,  4000] loss: 0.943\n",
            "[4,  6000] loss: 0.913\n",
            "[4,  8000] loss: 0.937\n",
            "[4, 10000] loss: 0.932\n",
            "[4, 12000] loss: 0.916\n",
            "[5,  2000] loss: 0.791\n",
            "[5,  4000] loss: 0.835\n",
            "[5,  6000] loss: 0.828\n",
            "[5,  8000] loss: 0.812\n",
            "[5, 10000] loss: 0.842\n",
            "[5, 12000] loss: 0.822\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 66.40 %\n"
          ]
        }
      ],
      "source": [
        "#  your code starts here\n",
        "import torch.optim as optim\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Updated hyperparameters\n",
        "num_conv_filters = 16\n",
        "conv_filter_size = 3\n",
        "fc1_output_size = 256\n",
        "fc2_output_size = 128\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(3, num_conv_filters, conv_filter_size)\n",
        "       self.pool = nn.MaxPool2d(2, 2)\n",
        "       self.conv2 = nn.Conv2d(num_conv_filters, 16, conv_filter_size)\n",
        "       self.fc1 = nn.Linear(16 * 6 * 6, fc1_output_size)\n",
        "       self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
        "       self.fc3 = nn.Linear(fc2_output_size, 10)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.pool(F.relu(self.conv1(x)))\n",
        "       x = self.pool(F.relu(self.conv2(x)))\n",
        "       x = torch.flatten(x, 1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   running_loss = 0.0\n",
        "   for i, data in enumerate(trainloader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = net(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       running_loss += loss.item()\n",
        "       if i % 2000 == 1999:\n",
        "           print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "           running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "   for data in testloader:\n",
        "       images, labels = data\n",
        "       outputs = net(images)\n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "\n",
        "# Save the model\n",
        "torch.save(net.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9g2oM40Plo3"
      },
      "source": [
        "The hyperparameters were updated but unforunately our accuracy went down. So let us update and tweark our hyper parameters again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD7sR3TgPgyT",
        "outputId": "141e9ab2-4619-47b9-8c27-a32c622b8a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.290\n",
            "[1,  4000] loss: 2.146\n",
            "[1,  6000] loss: 1.983\n",
            "[1,  8000] loss: 1.848\n",
            "[1, 10000] loss: 1.744\n",
            "[1, 12000] loss: 1.649\n",
            "[2,  2000] loss: 1.575\n",
            "[2,  4000] loss: 1.495\n",
            "[2,  6000] loss: 1.453\n",
            "[2,  8000] loss: 1.439\n",
            "[2, 10000] loss: 1.407\n",
            "[2, 12000] loss: 1.351\n",
            "[3,  2000] loss: 1.323\n",
            "[3,  4000] loss: 1.292\n",
            "[3,  6000] loss: 1.274\n",
            "[3,  8000] loss: 1.258\n",
            "[3, 10000] loss: 1.248\n",
            "[3, 12000] loss: 1.221\n",
            "[4,  2000] loss: 1.179\n",
            "[4,  4000] loss: 1.157\n",
            "[4,  6000] loss: 1.161\n",
            "[4,  8000] loss: 1.134\n",
            "[4, 10000] loss: 1.113\n",
            "[4, 12000] loss: 1.094\n",
            "[5,  2000] loss: 1.058\n",
            "[5,  4000] loss: 1.046\n",
            "[5,  6000] loss: 1.057\n",
            "[5,  8000] loss: 1.008\n",
            "[5, 10000] loss: 1.033\n",
            "[5, 12000] loss: 1.018\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 63.94 %\n"
          ]
        }
      ],
      "source": [
        "#  your code starts here\n",
        "import torch.optim as optim\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Updated hyperparameters\n",
        "num_conv_filters = 32\n",
        "conv_filter_size = 3\n",
        "fc1_output_size = 256\n",
        "fc2_output_size = 128\n",
        "learning_rate = 0.0003\n",
        "num_epochs = 5\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(3, num_conv_filters, conv_filter_size)\n",
        "       self.pool = nn.MaxPool2d(2, 2)\n",
        "       self.conv2 = nn.Conv2d(num_conv_filters, 16, conv_filter_size)\n",
        "       self.fc1 = nn.Linear(16 * 6 * 6, fc1_output_size)\n",
        "       self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
        "       self.fc3 = nn.Linear(fc2_output_size, 10)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.pool(F.relu(self.conv1(x)))\n",
        "       x = self.pool(F.relu(self.conv2(x)))\n",
        "       x = torch.flatten(x, 1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   running_loss = 0.0\n",
        "   for i, data in enumerate(trainloader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = net(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       running_loss += loss.item()\n",
        "       if i % 2000 == 1999:\n",
        "           print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "           running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "   for data in testloader:\n",
        "       images, labels = data\n",
        "       outputs = net(images)\n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "\n",
        "torch.save(net.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5feaMWKl9kh"
      },
      "source": [
        "Hyper paremeters were updated but the accuracy keeps going down. Let us tweak it a bit more to see if we can increase it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FNUCpzYShdc",
        "outputId": "ab07d67d-c967-4e7d-c08e-55cbb9b9edfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.302\n",
            "[1,  4000] loss: 2.297\n",
            "[1,  6000] loss: 2.285\n",
            "[1,  8000] loss: 2.232\n",
            "[1, 10000] loss: 2.088\n",
            "[1, 12000] loss: 1.981\n",
            "[2,  2000] loss: 1.889\n",
            "[2,  4000] loss: 1.842\n",
            "[2,  6000] loss: 1.818\n",
            "[2,  8000] loss: 1.770\n",
            "[2, 10000] loss: 1.734\n",
            "[2, 12000] loss: 1.682\n",
            "[3,  2000] loss: 1.609\n",
            "[3,  4000] loss: 1.595\n",
            "[3,  6000] loss: 1.578\n",
            "[3,  8000] loss: 1.559\n",
            "[3, 10000] loss: 1.526\n",
            "[3, 12000] loss: 1.496\n",
            "[4,  2000] loss: 1.447\n",
            "[4,  4000] loss: 1.453\n",
            "[4,  6000] loss: 1.442\n",
            "[4,  8000] loss: 1.427\n",
            "[4, 10000] loss: 1.417\n",
            "[4, 12000] loss: 1.400\n",
            "[5,  2000] loss: 1.390\n",
            "[5,  4000] loss: 1.343\n",
            "[5,  6000] loss: 1.332\n",
            "[5,  8000] loss: 1.328\n",
            "[5, 10000] loss: 1.314\n",
            "[5, 12000] loss: 1.318\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 54.07 %\n"
          ]
        }
      ],
      "source": [
        "#  your code starts here\n",
        "import torch.optim as optim\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Updated hyperparameters\n",
        "num_conv_filters = 64\n",
        "conv_filter_size = 3\n",
        "fc1_output_size = 512\n",
        "fc2_output_size = 256\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 5\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(3, num_conv_filters, conv_filter_size)\n",
        "       self.pool = nn.MaxPool2d(2, 2)\n",
        "       self.conv2 = nn.Conv2d(num_conv_filters, 16, conv_filter_size)\n",
        "       self.fc1 = nn.Linear(16 * 6 * 6, fc1_output_size)\n",
        "       self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
        "       self.fc3 = nn.Linear(fc2_output_size, 10)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.pool(F.relu(self.conv1(x)))\n",
        "       x = self.pool(F.relu(self.conv2(x)))\n",
        "       x = torch.flatten(x, 1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   running_loss = 0.0\n",
        "   for i, data in enumerate(trainloader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = net(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       running_loss += loss.item()\n",
        "       if i % 2000 == 1999:\n",
        "           print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "           running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "   for data in testloader:\n",
        "       images, labels = data\n",
        "       outputs = net(images)\n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "\n",
        "torch.save(net.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u-gtiemW5Kh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2cb_TGBW5h7",
        "outputId": "8497d028-1ecd-411b-8dc9-5fdf87e23743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.272\n",
            "[1,  4000] loss: 1.991\n",
            "[1,  6000] loss: 1.808\n",
            "[1,  8000] loss: 1.664\n",
            "[1, 10000] loss: 1.565\n",
            "[1, 12000] loss: 1.498\n",
            "[2,  2000] loss: 1.444\n",
            "[2,  4000] loss: 1.398\n",
            "[2,  6000] loss: 1.361\n",
            "[2,  8000] loss: 1.321\n",
            "[2, 10000] loss: 1.300\n",
            "[2, 12000] loss: 1.287\n",
            "[3,  2000] loss: 1.227\n",
            "[3,  4000] loss: 1.198\n",
            "[3,  6000] loss: 1.176\n",
            "[3,  8000] loss: 1.155\n",
            "[3, 10000] loss: 1.153\n",
            "[3, 12000] loss: 1.116\n",
            "[4,  2000] loss: 1.071\n",
            "[4,  4000] loss: 1.065\n",
            "[4,  6000] loss: 1.040\n",
            "[4,  8000] loss: 1.004\n",
            "[4, 10000] loss: 1.030\n",
            "[4, 12000] loss: 1.002\n",
            "[5,  2000] loss: 0.950\n",
            "[5,  4000] loss: 0.934\n",
            "[5,  6000] loss: 0.946\n",
            "[5,  8000] loss: 0.938\n",
            "[5, 10000] loss: 0.931\n",
            "[5, 12000] loss: 0.940\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 66.49 %\n"
          ]
        }
      ],
      "source": [
        "#  your code starts here\n",
        "import torch.optim as optim\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Updated hyperparameters\n",
        "num_conv_filters = 32\n",
        "conv_filter_size = 3\n",
        "fc1_output_size = 128\n",
        "fc2_output_size = 128\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 5\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(3, num_conv_filters, conv_filter_size)\n",
        "       self.pool = nn.MaxPool2d(2, 2)\n",
        "       self.conv2 = nn.Conv2d(num_conv_filters, 16, conv_filter_size)\n",
        "       self.fc1 = nn.Linear(16 * 6 * 6, fc1_output_size)\n",
        "       self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
        "       self.fc3 = nn.Linear(fc2_output_size, 10)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.pool(F.relu(self.conv1(x)))\n",
        "       x = self.pool(F.relu(self.conv2(x)))\n",
        "       x = torch.flatten(x, 1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   running_loss = 0.0\n",
        "   for i, data in enumerate(trainloader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = net(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       running_loss += loss.item()\n",
        "       if i % 2000 == 1999:\n",
        "           print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "           running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "   for data in testloader:\n",
        "       images, labels = data\n",
        "       outputs = net(images)\n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
        "\n",
        "torch.save(net.state_dict(), 'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91_ikvJAdYGN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze7jjVkmdYaD",
        "outputId": "8c3e3eb8-8377-4a12-e4d4-de2c9a589397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 1.784\n",
            "[1,  4000] loss: 1.497\n",
            "[1,  6000] loss: 1.370\n",
            "[1,  8000] loss: 1.317\n",
            "[1, 10000] loss: 1.244\n",
            "[1, 12000] loss: 1.201\n",
            "[2,  2000] loss: 1.110\n",
            "[2,  4000] loss: 1.095\n",
            "[2,  6000] loss: 1.056\n",
            "[2,  8000] loss: 1.040\n",
            "[2, 10000] loss: 1.012\n",
            "[2, 12000] loss: 0.977\n",
            "[3,  2000] loss: 0.910\n",
            "[3,  4000] loss: 0.907\n",
            "[3,  6000] loss: 0.887\n",
            "[3,  8000] loss: 0.890\n",
            "[3, 10000] loss: 0.881\n",
            "[3, 12000] loss: 0.877\n",
            "[4,  2000] loss: 0.759\n",
            "[4,  4000] loss: 0.780\n",
            "[4,  6000] loss: 0.773\n",
            "[4,  8000] loss: 0.790\n",
            "[4, 10000] loss: 0.782\n",
            "[4, 12000] loss: 0.782\n",
            "[5,  2000] loss: 0.663\n",
            "[5,  4000] loss: 0.678\n",
            "[5,  6000] loss: 0.677\n",
            "[5,  8000] loss: 0.694\n",
            "[5, 10000] loss: 0.694\n",
            "[5, 12000] loss: 0.705\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 69.46 %\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "num_conv_filters = 32\n",
        "conv1_filter_size = 5\n",
        "conv2_filter_size = 3\n",
        "padding = 2\n",
        "fc1_output_size = 256\n",
        "fc2_output_size = 128\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 15\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(3, num_conv_filters, conv1_filter_size, padding=padding)\n",
        "       self.pool = nn.MaxPool2d(2, 2)\n",
        "       self.conv2 = nn.Conv2d(num_conv_filters, 16, conv2_filter_size)\n",
        "       self.fc1 = nn.Linear(16 * 7 * 7, fc1_output_size)\n",
        "       self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
        "       self.fc3 = nn.Linear(fc2_output_size, 10)\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.pool(F.relu(self.conv1(x)))\n",
        "       x = self.pool(F.relu(self.conv2(x)))\n",
        "       x = torch.flatten(x, 1)\n",
        "       x = F.relu(self.fc1(x))\n",
        "       x = F.relu(self.fc2(x))\n",
        "       x = self.fc3(x)\n",
        "       return x\n",
        "\n",
        "net = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   running_loss = 0.0\n",
        "   for i, data in enumerate(trainloader, 0):\n",
        "       inputs, labels = data\n",
        "       optimizer.zero_grad()\n",
        "       outputs = net(inputs)\n",
        "       loss = criterion(outputs, labels)\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       running_loss += loss.item()\n",
        "       if i % 2000 == 1999:\n",
        "           print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "           running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "   for data in testloader:\n",
        "       images, labels = data\n",
        "       outputs = net(images)\n",
        "       _, predicted = torch.max(outputs.data, 1)\n",
        "       total += labels.size(0)\n",
        "       correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwfO8ZaYi05u"
      },
      "source": [
        "Adding in a extra hyper parameter of padding helped us increase our accuracy to a all-time high of almost 70%.\n",
        "\n",
        "Achieving a 70% accuracy on the CIFAR-10 test set reflects the efficacy of our convolutional neural network architecture and training regimen. With two convolutional layers followed by max-pooling and fully connected layers, our model adeptly captures hierarchical features from CIFAR-10 images. The choice of filter sizes and the number of filters in each layer contributes to the model's feature extraction capabilities. Utilizing max-pooling layers enhances translation invariance and computational efficiency. Training with the Adam optimizer and a learning rate of 0.0005 for 15 epochs ensures effective parameter optimization. The model's ability to generalize is evidenced by its commendable accuracy in classifying diverse images across ten categories. Continual exploration of alternative architectures and hyperparameters may further refine the model's performance and adaptability in real-world scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6FqzS3z1hrI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Transfer Learning:  Use AlexNet as a fixed feature extractor\n",
        "So far we have trained very small neural networks from scratch. As mentioned in the previous problem,\n",
        "modern neural networks are much larger and more difficult to train and validate. In practice, it is rare to train\n",
        "such large networks from scratch. This is because it is difficult to obtain both the massive datasets and the\n",
        "computational resources required to train such networks.\n",
        "\n",
        "Instead of training a network from scratch, in this problem, we will use a network that has already been trained\n",
        "on a very large dataset (ImageNet) and adjust it for the task at hand. This process of adapting weights in a\n",
        "model trained for another task is known as **transfer learning**.\n",
        "\n",
        "Begin with the pretrained **AlexNet** model from `torchvision.models` for the following tasks below. AlexNet\n",
        "achieved an early breakthrough performance on ImageNet and was instrumental in sparking the deep\n",
        "learning revolution in 2012.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.alexnet(pretrained=True)\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "model.classifier[6] = nn.Linear(4096, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyXN_in7Pz-W",
        "outputId": "e2e997c8-08b9-4f2b-c255-272b2c29d2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:07<00:00, 32.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NcS6cNB8gYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fd2cd8-0d2f-483d-c82c-675dec70b5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated AlexNet's classifier:\n",
            "Sequential(\n",
            "  (0): Dropout(p=0.5, inplace=False)\n",
            "  (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 0.752858481691469\n",
            "Epoch 2, Loss: 0.6570306451195647\n",
            "Epoch 3, Loss: 0.6347529567644724\n",
            "Epoch 4, Loss: 0.6248216960588684\n",
            "Epoch 5, Loss: 0.6193064589748907\n",
            "Epoch 6, Loss: 0.6174531828640671\n",
            "Epoch 7, Loss: 0.610101635422548\n",
            "Epoch 8, Loss: 0.6058865510822867\n",
            "Epoch 9, Loss: 0.6089087691148529\n",
            "Epoch 10, Loss: 0.6065275648137187\n",
            "Accuracy: 81.38%\n"
          ]
        }
      ],
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Freeze all parameters in the network\n",
        "for param in alexnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the classifier to output 10 classes\n",
        "alexnet.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alexnet.to(device)\n",
        "\n",
        "print(\"Updated AlexNet's classifier:\")\n",
        "print(alexnet.classifier)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Download and prepare CIFAR10 datasets\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(alexnet.classifier[6].parameters(), lr=0.001)\n",
        "\n",
        "def train(model, loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for data, targets in loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(loader)}')\n",
        "\n",
        "# Train the model\n",
        "train(alexnet, train_loader)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total}%')\n",
        "\n",
        "evaluate(alexnet, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEbf4r_v86WL"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Transfer Learning: Use AlexNet as initialization\n",
        "The second approach to transfer learning is to fine-tune the weights of the pretrained network, in addition to training the new classification layer. In this approach, all network weights\n",
        "are updated at every training iteration; we simply use the existing AlexNet weights as the â€œinitializationâ€\n",
        "for our network (except for the weights in the new classification layer, which will be initialized using\n",
        "whichever method is specified in the constructor) prior to training on CIFAR-10.\n",
        "\n",
        "**Note**: Fine-tune AlexNet on\n",
        "CPU takes an insame amount of time, so we recommend you to use Google Colab, which has free GPU\n",
        "access. To enable GPU for the notebook: Navigate to Editâ†’Notebook Settings. select GPU from the\n",
        "Hardware Accelerator drop-down. For information about training on GPU, check the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Modify the classifier to output 10 classes\n",
        "alexnet.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alexnet.to(device)\n",
        "\n",
        "# Prepare CIFAR-10 data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Training configuration\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(alexnet.parameters(), lr=0.0001)\n",
        "\n",
        "# Training function\n",
        "def train(model, loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for data, targets in loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {total_loss / len(loader)}')\n",
        "\n",
        "# Evaluate function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    print(f'Accuracy: {100 * correct / total}%')\n",
        "\n",
        "# Train the model\n",
        "train(alexnet, train_loader)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "evaluate(alexnet, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-tSuy_ex7g4",
        "outputId": "3ed3d83c-08c9-472c-d06d-9e8d89ff1d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 0.5597006424003855\n",
            "Epoch 2, Loss: 0.30726274526904307\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}